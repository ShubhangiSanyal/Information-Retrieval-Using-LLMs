{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install chromadb"
      ],
      "metadata": {
        "id": "MsuXFNMk1kD7"
      },
      "id": "MsuXFNMk1kD7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain"
      ],
      "metadata": {
        "id": "vOb3AgPt2A0S"
      },
      "id": "vOb3AgPt2A0S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence_transformers"
      ],
      "metadata": {
        "id": "OUivyC6T2PIN"
      },
      "id": "OUivyC6T2PIN",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef663270-9c8f-4d22-afe9-c6ebd38dc027",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-23T08:19:18.576133Z",
          "start_time": "2023-10-23T08:19:18.572018Z"
        },
        "tags": [],
        "id": "ef663270-9c8f-4d22-afe9-c6ebd38dc027"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import chromadb\n",
        "from langchain.retrievers.merger_retriever import MergerRetriever\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
        "from langchain.document_transformers import (\n",
        "    EmbeddingsRedundantFilter,\n",
        "    EmbeddingsClusteringFilter,\n",
        ")\n",
        "from langchain.retrievers.document_compressors import DocumentCompressorPipeline\n",
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "19c1c81e",
      "metadata": {
        "id": "19c1c81e"
      },
      "source": [
        "## Get the Embedding Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7b2b839",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-23T08:16:33.768026Z",
          "start_time": "2023-10-23T08:15:58.421696Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490,
          "referenced_widgets": [
            "52722c76d9494196913c3f23b1478b10",
            "b227e7088bcd49e885ba9d4ce9aa8560",
            "57c613027ba34100aa985539d03cfb26",
            "4e7f9aed3d244e4b91ba2d5b62febb09",
            "72daefc4f5ba48d99cc221ccc87fc0b9",
            "c1b4a13aca454b0fa06de24d8ebd2702",
            "82420dfcf16c497087e1965e7aa2e100",
            "d576306dad004d23b262099730b1f8ff",
            "8655fb9499f24995b6fb7c60035d0a34",
            "53e49897eb1e40b39b7f5c549eb456d8",
            "21b86c7634e64142a7d29a00b0709b60",
            "83a4b30bd4b545edb4e0c2eca0f22548",
            "3e886d5383b8447390bb2208fd943872",
            "63b48bdfe3284acabab332a14c821651",
            "ecee89595dde487b9b16084855e3c138",
            "6d680f5aa55f4455b9973b21cedf6969",
            "bdb8f3069ffc411482db4bfa8a0889e1",
            "ebc44c8e38004170aee04b241ca7a730",
            "993990dbed0b4ea797f44a98f0ae0d2c",
            "737429dcdfc4400c80535c4d3021362f",
            "5467eb7115c744f096fddcdbfd1473f5",
            "e603d283ca6544e4b4af596af24b3113",
            "947bce9f66af49c8b1e9d20447bd8174",
            "57728d7a626844ef9ce0def421a9439a",
            "911eedb7d6bd47b3bb37c95855e0c746",
            "7e1daecb0bde48c2a396552b91ccdb7d",
            "400d377889c743caa1ae6037503a958b",
            "bb48cb33873146baaed8154b020098ca",
            "c8f1cc6e5ab548f1ac2da5aef4f416b5",
            "3f3b578a95f343b09553c173683a1156",
            "9b2dd7d4d6bb4e5f87dbc67d136979f3",
            "9f01326ac2a140ebb155720b5b19efdc",
            "5b75481deec3498bbf0ef05056afd5d7",
            "bae66bb241b447e0bf0b1fc1666a294f",
            "75d22f1876494c9787bddabb3190350f",
            "b21aa4a9277d4ce2ae4b7f09717b3d1a",
            "1ba37c69aece4519bb276bb46e6ad74c",
            "4f01964b42fb449cbbfed139503eaf0e",
            "2f70f0da54c4430998ee42d34c58f53d",
            "fa41f3d4b4a64f0881c6433052c026ba",
            "88acdf70f2b743a5833ba8e1461eed65",
            "05859f0a72544fc182713af8a5337238",
            "3c0ce833a0554e10a5087f73bb5d6d7c",
            "cc440aff42e94f41a2ec255012d4c730",
            "e2ce8bce3fea4b57a82d30908f57dd12",
            "caa7c33de4a1432f84bdc2f622ebbe69",
            "63b551023b4844a68dd45aa8431063ad",
            "222912e65207443988f2141c4a9617f9",
            "b1b3f40102004a9c9c64b5a243abdcf8",
            "e9732e1248f74903aff8a62d443bb1e9",
            "96f9ef30dbab4bf2a81d9ab1a9c49699",
            "60c1e5a5dbe24e078e6affad3acbf797",
            "cb0eb05e12314f089595a66469d51901",
            "4f2783168c8d4ea1bda110b40f0a28c7",
            "c83956f92b044f159831105d4c49d9cf",
            "667448ad74f24ce5b09800391b5515f1",
            "00b334f4920f4e6089ae6acf9117416b",
            "7cb5b7b3fc1c4d48aa96df6ebacc3761",
            "179f48b91e94447d98d206e1fe425d69",
            "ee8bfdb734054c778f95d146219c3765",
            "5683ae50342f4cd0b650ae7cada9fdf1",
            "e4d830beca6049d98871fc838e3c8a8c",
            "5079159317554c6a993a1b06cfba923b",
            "20031b89edb34382b6dd355944c7b76b",
            "7da5cb654f8d433fb8c5f2cbc09566fc",
            "91714fc0c83b417b8e51689b7cfa1b7c",
            "55f2f2c7868b4cc68948877a05dded73",
            "4a2aeab7aa8f418e8cef2cf4d05fc104",
            "5045a97a2df54f9b83e32914a3f1f248",
            "29f5337b0eda48fd8bb1607f734fccf7",
            "7b03263645b54559947e00e5d846e0ca",
            "f44b57430fc841dfa9b05a23e502b9e7",
            "1753b069772940f499372daa478d060c",
            "b854e636dc2b471dbe344af781c24c3b",
            "6b99aac606454a61b8d6b9da2fb4c88a",
            "6596d8fcd4df4ece81d53797fc449152",
            "3745233681524ab688f596c323deda22",
            "0b8e8afea10a46aabf54f563f1e14903",
            "4e051a42886048d5901bcffed3554b14",
            "825a934bef3443479eda76bfc1c4426a",
            "4d19c4411b8648d9a71e305f976f67c9",
            "410a036dd20c4bad805a3c5564bde39d",
            "8d4b0f57b4044a8c83924fca82ef6aaf",
            "967a9a42d1964637a7fc70bce9f9a946",
            "cabd809012e844968303073872cb0f0d",
            "a78668de689646c5b73a207280ea55ab",
            "ec9f377b00574bb8a77f9392853ca44a",
            "600d8b87767c434db33df36ff2124768",
            "d06e51dd6bba44c6a38b72f26b8ebc1c",
            "b46aaec5e0ea4478bf4026ffc1c82875",
            "782e783d8de1471d9449848e655ecd5d",
            "98724648be1e45fbafbcd2368bef2028",
            "8ab31c4b2afc41a89b874f728c3cce6d",
            "4f323909a0504b81a8432aa6eb26be36",
            "f21731ddabf64d8cbb55c8b6d7b8513d",
            "f2c9de03b9b7417a84e1027537cfe7b4",
            "7e3f1e0f6e564592ad62b275a42172bc",
            "a7f8e72e9a7047e2b6992f89659df712",
            "76bf61fa2f26429580bbdd58f2a26ec1",
            "058425f9a19d4156bb815c12009b38a4",
            "3bccc588c88641ed8a8da355234c0908",
            "5bd49c7001aa4bf0b3c5678462c64aa9",
            "729c86c2dae9481db49831a99d496576",
            "ef83cdbd05a04521be1ed3fee589e38f",
            "aed5b831f46348bab5565ede4b5ca8f2",
            "7a591bdc180a4df98f3f2c1a94f2e22e",
            "3b0848ad88304a9c86aac7acc005c7f0",
            "252a1633735d4ef7a67a4f1ef22c2204",
            "d2bf684f637c437baa5a1edf103cd0b7",
            "6cafd6635d8e49439968bf7a91a526df",
            "277dc925a8b3456b995d3d05d2acfe65",
            "46f29f90caae4b8991a7315d7fe88bbc",
            "090e88d6bd9d4d9e9f1e1a938cfe8568",
            "81b154d1b96d4c5db5c9bda2a1a5bfa3",
            "68b1f2f9cd094eef9f5daab6a17d0062",
            "8975b5b0fb494ef1977804162ab484b3",
            "d42dd22eb10549a298baf795a275353d",
            "2e73e76cb1f044e29b4e8feaadcb49fe",
            "2409eaac25084d23ba1e937886129785",
            "0e94231cb64b4b708bbc9ddcda0891b9",
            "7fe6dac60d74454da08d39f898cba0cb"
          ]
        },
        "id": "e7b2b839",
        "outputId": "f63c8ce3-0a99-4ab9-952a-54ae811d54a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52722c76d9494196913c3f23b1478b10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83a4b30bd4b545edb4e0c2eca0f22548"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/90.3k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "947bce9f66af49c8b1e9d20447bd8174"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bae66bb241b447e0bf0b1fc1666a294f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/720 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2ce8bce3fea4b57a82d30908f57dd12"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.34G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "667448ad74f24ce5b09800391b5515f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "55f2f2c7868b4cc68948877a05dded73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b8e8afea10a46aabf54f563f1e14903"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d06e51dd6bba44c6a38b72f26b8ebc1c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "058425f9a19d4156bb815c12009b38a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "277dc925a8b3456b995d3d05d2acfe65"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Model Loaded..........\n"
          ]
        }
      ],
      "source": [
        "model_name = \"BAAI/bge-large-en\"\n",
        "model_kwargs = {'device': 'cpu'}\n",
        "encode_kwargs = {'normalize_embeddings': False}\n",
        "hf = HuggingFaceBgeEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs=model_kwargs,\n",
        "    encode_kwargs=encode_kwargs\n",
        ")\n",
        "print(\"Embedding Model Loaded..........\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cd3fdac",
      "metadata": {
        "id": "5cd3fdac"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "def process_audio_text(audio_filename):\n",
        "    # Load text from the audio file\n",
        "    loader = TextLoader(audio_filename)\n",
        "    text_audio = loader.load()\n",
        "\n",
        "    # Split text using RecursiveCharacterTextSplitter\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "    text_content_audio = text_splitter.split_documents(text_audio)\n",
        "\n",
        "    return text_content_audio"
      ],
      "metadata": {
        "id": "WhwlNESUQmVX"
      },
      "id": "WhwlNESUQmVX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "audio_files=[\"audio_1.txt\",\"audio_2.txt\",\"audio_3.txt\",\"audio_4.txt\",\"audio_5.txt\"]"
      ],
      "metadata": {
        "id": "ss4c8jkYRfQQ"
      },
      "id": "ss4c8jkYRfQQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_contents={}\n",
        "for i,audio_file in enumerate(audio_files):\n",
        "  content=process_audio_text(audio_file)\n",
        "  file_name=f\"text_content_audio_{i+1}\"\n",
        "  text_contents[file_name]=content"
      ],
      "metadata": {
        "id": "_PM-sCUdRxU1"
      },
      "id": "_PM-sCUdRxU1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_contents['text_content_audio_1'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1y3FH3WeTCpb",
        "outputId": "77e03e4b-179d-4671-a1e2-7cabfd5ada4f"
      },
      "id": "1y3FH3WeTCpb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content=\"So welcome to this first lecture on this course, DMML. So today I will try to set some context for the course and also tell you a little bit about start the first topic. So I have set up some information just a few minutes back on the moodle page to give you information about the list of topics, roughly that we plan to cover and also about the assessment and all that. So if you have any questions on that, you can look it up and maybe next time we can discuss that. So I won't spend too much time right now on the administrative aspects of the course. We'll just start looking at what we are going to do in this course. So if you look at the title of the course, it clearly says two things. It says data mining and machine learning. In a sense, this is a kind of historical thing. That's how this course was initially created some many years back. So if you want to look at the two parts of the title in some detail. So data mining is a loose term which talks about identifying some hidden\", metadata={'source': 'audio_1.txt'})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6420577a",
      "metadata": {
        "id": "6420577a"
      },
      "source": [
        "## Create and Store Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ef86740",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-23T08:36:02.439715Z",
          "start_time": "2023-10-23T08:32:26.262422Z"
        },
        "id": "5ef86740"
      },
      "outputs": [],
      "source": [
        "audio1_store = Chroma.from_documents(text_contents['text_content_audio_1'], hf, collection_metadata={\"hnsw:space\": \"cosine\"}, persist_directory=\"audio1_chroma_cosine\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !zip -r /content/audio1_chroma_cosine.zip /content/audio1_chroma_cosine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9-3-JVHVaQ4Q",
        "outputId": "9dbbb504-0b97-471c-dc90-45ce0fcdf035"
      },
      "id": "9-3-JVHVaQ4Q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/audio1_chroma_cosine/ (stored 0%)\n",
            "  adding: content/audio1_chroma_cosine/23e64686-b861-4f1e-8411-c279494758b4/ (stored 0%)\n",
            "  adding: content/audio1_chroma_cosine/23e64686-b861-4f1e-8411-c279494758b4/header.bin (deflated 61%)\n",
            "  adding: content/audio1_chroma_cosine/23e64686-b861-4f1e-8411-c279494758b4/length.bin (deflated 37%)\n",
            "  adding: content/audio1_chroma_cosine/23e64686-b861-4f1e-8411-c279494758b4/link_lists.bin (stored 0%)\n",
            "  adding: content/audio1_chroma_cosine/23e64686-b861-4f1e-8411-c279494758b4/data_level0.bin (deflated 100%)\n",
            "  adding: content/audio1_chroma_cosine/chroma.sqlite3 (deflated 53%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f31a053",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-23T08:49:54.220901Z",
          "start_time": "2023-10-23T08:49:11.975656Z"
        },
        "id": "7f31a053"
      },
      "outputs": [],
      "source": [
        "audio2_store = Chroma.from_documents(text_contents['text_content_audio_2'], hf, collection_metadata={\"hnsw:space\": \"cosine\"}, persist_directory=\"audio2_chroma_cosine\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " !zip -r /content/audio2_chroma_cosine.zip /content/audio2_chroma_cosine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEFYquTYcOuV",
        "outputId": "2c131ced-05e8-43fa-bb5b-157b18370ec2"
      },
      "id": "BEFYquTYcOuV",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/audio2_chroma_cosine/ (stored 0%)\n",
            "  adding: content/audio2_chroma_cosine/39fe4e3b-be9c-44a2-84d4-5c8f189c301d/ (stored 0%)\n",
            "  adding: content/audio2_chroma_cosine/39fe4e3b-be9c-44a2-84d4-5c8f189c301d/header.bin (deflated 61%)\n",
            "  adding: content/audio2_chroma_cosine/39fe4e3b-be9c-44a2-84d4-5c8f189c301d/length.bin (deflated 30%)\n",
            "  adding: content/audio2_chroma_cosine/39fe4e3b-be9c-44a2-84d4-5c8f189c301d/link_lists.bin (stored 0%)\n",
            "  adding: content/audio2_chroma_cosine/39fe4e3b-be9c-44a2-84d4-5c8f189c301d/data_level0.bin (deflated 7%)\n",
            "  adding: content/audio2_chroma_cosine/chroma.sqlite3 (deflated 50%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio3_store = Chroma.from_documents(text_contents['text_content_audio_3'], hf, collection_metadata={\"hnsw:space\": \"cosine\"}, persist_directory=\"audio3_chroma_cosine\")"
      ],
      "metadata": {
        "id": "fuNALvlgTlCv"
      },
      "id": "fuNALvlgTlCv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " !zip -r /content/audio3_chroma_cosine.zip /content/audio3_chroma_cosine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGhxdNzlcbsW",
        "outputId": "3818929e-866c-4574-ccd5-af2a4ea678b0"
      },
      "id": "eGhxdNzlcbsW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/audio3_chroma_cosine/ (stored 0%)\n",
            "  adding: content/audio3_chroma_cosine/2cd5c8b3-2d84-4649-8d4a-0448b568a700/ (stored 0%)\n",
            "  adding: content/audio3_chroma_cosine/2cd5c8b3-2d84-4649-8d4a-0448b568a700/header.bin (deflated 61%)\n",
            "  adding: content/audio3_chroma_cosine/2cd5c8b3-2d84-4649-8d4a-0448b568a700/length.bin (deflated 98%)\n",
            "  adding: content/audio3_chroma_cosine/2cd5c8b3-2d84-4649-8d4a-0448b568a700/link_lists.bin (stored 0%)\n",
            "  adding: content/audio3_chroma_cosine/2cd5c8b3-2d84-4649-8d4a-0448b568a700/data_level0.bin (deflated 8%)\n",
            "  adding: content/audio3_chroma_cosine/chroma.sqlite3 (deflated 53%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio4_store = Chroma.from_documents(text_contents['text_content_audio_4'], hf, collection_metadata={\"hnsw:space\": \"cosine\"}, persist_directory=\"audio4_chroma_cosine\")"
      ],
      "metadata": {
        "id": "fD2CVCTQTrmy"
      },
      "id": "fD2CVCTQTrmy",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " !zip -r /content/audio4_chroma_cosine.zip /content/audio4_chroma_cosine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ib0STE_Qcqc9",
        "outputId": "8d17f19b-8444-40f3-f3ae-5c03dbc6fb82"
      },
      "id": "ib0STE_Qcqc9",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/audio4_chroma_cosine/ (stored 0%)\n",
            "  adding: content/audio4_chroma_cosine/9af56ffe-cdde-4811-853d-d366cdcb2eee/ (stored 0%)\n",
            "  adding: content/audio4_chroma_cosine/9af56ffe-cdde-4811-853d-d366cdcb2eee/header.bin (deflated 61%)\n",
            "  adding: content/audio4_chroma_cosine/9af56ffe-cdde-4811-853d-d366cdcb2eee/length.bin (deflated 32%)\n",
            "  adding: content/audio4_chroma_cosine/9af56ffe-cdde-4811-853d-d366cdcb2eee/link_lists.bin (stored 0%)\n",
            "  adding: content/audio4_chroma_cosine/9af56ffe-cdde-4811-853d-d366cdcb2eee/data_level0.bin (deflated 94%)\n",
            "  adding: content/audio4_chroma_cosine/chroma.sqlite3 (deflated 50%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "audio5_store = Chroma.from_documents(text_contents['text_content_audio_5'], hf, collection_metadata={\"hnsw:space\": \"cosine\"}, persist_directory=\"audio5_chroma_cosine\")"
      ],
      "metadata": {
        "id": "6CVpZO-xTsf3"
      },
      "id": "6CVpZO-xTsf3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " !zip -r /content/audio5_chroma_cosine.zip /content/audio5_chroma_cosine"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAi7sGXwcvxn",
        "outputId": "bbc84bb2-ecbc-4706-d83b-e08f46331a1b"
      },
      "id": "AAi7sGXwcvxn",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/audio5_chroma_cosine/ (stored 0%)\n",
            "  adding: content/audio5_chroma_cosine/c048879c-0cc0-4984-8f6b-74bc56de0af7/ (stored 0%)\n",
            "  adding: content/audio5_chroma_cosine/c048879c-0cc0-4984-8f6b-74bc56de0af7/header.bin (deflated 61%)\n",
            "  adding: content/audio5_chroma_cosine/c048879c-0cc0-4984-8f6b-74bc56de0af7/length.bin (deflated 37%)\n",
            "  adding: content/audio5_chroma_cosine/c048879c-0cc0-4984-8f6b-74bc56de0af7/link_lists.bin (stored 0%)\n",
            "  adding: content/audio5_chroma_cosine/c048879c-0cc0-4984-8f6b-74bc56de0af7/data_level0.bin (deflated 17%)\n",
            "  adding: content/audio5_chroma_cosine/chroma.sqlite3 (deflated 54%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aa1dfda5",
      "metadata": {
        "id": "aa1dfda5"
      },
      "source": [
        "## Load Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9faea31c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-23T09:01:38.800968Z",
          "start_time": "2023-10-23T09:01:38.791486Z"
        },
        "id": "9faea31c"
      },
      "outputs": [],
      "source": [
        "load_audio1_store = Chroma(persist_directory=\"audio1_chroma_cosine\", embedding_function=hf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4767de7a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-23T09:02:04.719254Z",
          "start_time": "2023-10-23T09:02:04.709131Z"
        },
        "id": "4767de7a"
      },
      "outputs": [],
      "source": [
        "load_audio2_store = Chroma(persist_directory=\"audio2_chroma_cosine\", embedding_function=hf)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_audio3_store = Chroma(persist_directory=\"audio3_chroma_cosine\", embedding_function=hf)"
      ],
      "metadata": {
        "id": "sdSJBQZxc-a1"
      },
      "id": "sdSJBQZxc-a1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_audio4_store = Chroma(persist_directory=\"audio4_chroma_cosine\", embedding_function=hf)"
      ],
      "metadata": {
        "id": "QCpK3TVPdDR3"
      },
      "id": "QCpK3TVPdDR3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_audio5_store = Chroma(persist_directory=\"audio5_chroma_cosine\", embedding_function=hf)"
      ],
      "metadata": {
        "id": "2RDQealbdGF3"
      },
      "id": "2RDQealbdGF3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "bbe6d5bf",
      "metadata": {
        "id": "bbe6d5bf"
      },
      "source": [
        "## Init Merge Retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dca28b13",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-23T09:02:52.862205Z",
          "start_time": "2023-10-23T09:02:52.857127Z"
        },
        "id": "dca28b13"
      },
      "outputs": [],
      "source": [
        "retriever_audio1 = load_audio1_store.as_retriever(search_type = \"similarity\", search_kwargs = {\"k\":3})\n",
        "\n",
        "retriever_audio2 = load_audio2_store.as_retriever(search_type = \"similarity\", search_kwargs = {\"k\":3})\n",
        "\n",
        "retriever_audio3 = load_audio3_store.as_retriever(search_type = \"similarity\", search_kwargs = {\"k\":3})\n",
        "\n",
        "retriever_audio4 = load_audio4_store.as_retriever(search_type = \"similarity\", search_kwargs = {\"k\":3})\n",
        "\n",
        "retriever_audio5 = load_audio5_store.as_retriever(search_type = \"similarity\", search_kwargs = {\"k\":3})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cf4780e",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-23T09:02:54.002581Z",
          "start_time": "2023-10-23T09:02:53.999837Z"
        },
        "id": "7cf4780e"
      },
      "outputs": [],
      "source": [
        "lotr = MergerRetriever(retrievers=[retriever_audio1, retriever_audio2,retriever_audio3,retriever_audio4,retriever_audio5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb9ccdc9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2023-10-23T09:02:54.636861Z",
          "start_time": "2023-10-23T09:02:54.631590Z"
        },
        "id": "fb9ccdc9",
        "outputId": "5f280754-741a-43d5-97d2-43db6247e9de",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MergerRetriever(retrievers=[VectorStoreRetriever(tags=['Chroma', 'HuggingFaceBgeEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7c4853f65900>, search_kwargs={'k': 3}), VectorStoreRetriever(tags=['Chroma', 'HuggingFaceBgeEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7c4853f65c00>, search_kwargs={'k': 3}), VectorStoreRetriever(tags=['Chroma', 'HuggingFaceBgeEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7c4853f67130>, search_kwargs={'k': 3}), VectorStoreRetriever(tags=['Chroma', 'HuggingFaceBgeEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7c4853f67a00>, search_kwargs={'k': 3}), VectorStoreRetriever(tags=['Chroma', 'HuggingFaceBgeEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7c4853f673d0>, search_kwargs={'k': 3})])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "lotr"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28a46e7e",
      "metadata": {
        "id": "28a46e7e"
      },
      "source": [
        "## Perform Semantic Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d61909f7",
      "metadata": {
        "id": "d61909f7"
      },
      "outputs": [],
      "source": [
        "query=\" What are some challenges associated with data collection?\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs = lotr.get_relevant_documents(query)\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5_YbZuz6tUJ",
        "outputId": "62e66ee6-b3af-4079-c28d-daa726ef19ac"
      },
      "id": "J5_YbZuz6tUJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"entered by somebody and then converted to electronic forms. So that would be, there would be two levels of potential sources for errors. The person writing down the information and then the person typing in the information. Now, gradually these kind of electronic forms are spilled in directly, so at least the source of the error is reduced to one step. But still, people mistype things. I mean, there are any number of situations where people type their email address wrong and so notifications don't reach them and so on. So there is this data collection. How do you collect the data and how do you clean it? And the third thing is, how do you make it uniform? So when data is being collected by different people, they may collect different things. And for instance, if you look at the government, typically the government collects data in different forms. For instance, there is a public distribution system which the ration shops, so they collect some information about who is collecting ration\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"have to, in the example that you gave, you would have to first separate out the data for these, say, the people who buy one month groceries at a time from those who buy at more frequent intervals and then analyze them separately, because together the data doesn't actually make sense. So last time, if you remember, I talked about this unsupervised. So maybe one thing that you need to do when you have something large is to basically look at the transactions and categorize them according to some criteria, maybe by the size of the basket. And then you will find that there are maybe a lot of people who buy five items at a time. There are people who buy ten to 20 items at a time. There are people who buy 40 items at a time. And maybe you need to then apply the model separately to each of these clusters. So all of these things are not a one size fits all solution. And also, it's not that one approach on its own is going to solve the problem at any given time. So you need to have a kind of\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content='been collected correctly. So as we said, the main issue is really how to ask the questions and what this means. Sorry, sir, I have a question. Yeah. Sir, once we know that the data is young, we are making a prediction and it come out that young. So like other attribute is not relevant other than it has job or not, and then we are not going to look at other attributes. Yeah, but remember that which attributes to look like vary from one path to another. So maybe in this case, right, so what we are saying is that if they are young, we only need the job, right? But if they are middle aged, we need to know the house. So for different combinations, so they may not occur together. I agree, in any decision, but each of these plays a role somewhere. Now, if there is another attribute which never plays a role, as we will see the next tree as that example. Right? So if you look at this, this is a different tree for the same data set. So instead of first asking the age, we ask whether you own a', metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"picked up is because we have not interpreted. So you might ask, okay, why passport number? But it could be something indirect, like, it could be some kind of an encoded timestamp. It could be some actions which are recorded in some system, and then one of the columns records somehow the timestamp, and no two events happen with the same timestamp. So there could be any number of hidden reasons why something is actually unique. And either you have to clean up the data and check it, or you have to build a safeguard against this happening. It may or may not happen, but I just wanted to bring this up because this is a byproduct of the algorithm that we have now. It's a shortcoming. It's a shortcoming in the sense that if we apply the algorithm that we have now, right now, in such a situation, blindly, then we will end up with this kind of curious choice right up front. It will tell us that the only question you need to ask is, say, the passport number of the patient, and then you will be\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content='It asks one vertical question and one horizontal question and isolates that. Similarly, there is a blue point in the middle here, right there on the right hand side, you can see where my cursor is, that blue part. So here it basically create just to pull that blue point out. So this is, again, kind of an experimental or empirical justification of the argument that smaller trees will give you more manageable and more understandable marks. The tree on the right sort of makes mistakes, but you can kind of figure out why it is drawing the lines where they are. And there are going to be a few anomalies with it. The left hand side is arguably got fewer anomalies, but it has created these strange islands of yellow at the bottom and the spike of green in the middle and all that, which may not make much sense. So this is as far as constraining the thing. Now, if I take this. So now we go back to our, this iris data set. So iris data set had capital X as the input. That was our original input.', metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"of elearning platforms, there's a lot of emphasis on trying to structure topics in such a way that students who find difficulty, you can identify why they are facing difficulties. So you want to think of these concepts that you're teaching as these items. And basket is now a set of concepts. And if you look at a concept which is difficult to learn, maybe there is a connection to another concept which is also difficult to learn. So you might want to group this. So people who misunderstand a also misunderstand b. And therefore maybe the problems has to start by fixing b. And another place where this is used is in kind of similarities of documents. So if two documents share words, then you can think they are similar. So you can think of documents. Or if two words appear rather in many documents, you can think they are similar. So if you say that wherever x appears, y also appears, then it may mean that x and y are actually related concepts. So this is the context. So the real question is\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"can measure it, but you cannot. In some sense, if you could validate it, then this whole problem becomes much simpler. But the whole difficulty with machine learning is exactly this, that there is no sensible way to predict the behavior or even when it will fail. Even if you could say that this is likely to work well here and not likely to work well there that itself would be a huge improvement, not even necessarily a very precise quantification, but just some indication. But all these are very speculative. So that's a huge challenge. So there are some theoretical things you can say which we may not, may or may not get to in this course. But it's a big problem. This is the so called generalization problem. So that's what basically, if you build association rules, is it going to hold or not? I don't know. Okay, sir, I had a question. We have been talking about items and transactions, but we haven't anywhere spoken about whether one customer, suppose if you're talking about somebody\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content=\"and these subtables be destroyed. And when you stop, you ask whether it's uniform or whether there's a majority. So this is what we were discussing. So a non uniform leaf node where I have run out of questions, but I have different classes. So basically I have identical combination of attributes, but different classes is something which indicates that our data is somehow incomplete. The attributes are not capturing all the criteria which are actually used for the classification. There are some hidden attributes which are not being captured, and this happens quite often. So we can't derive this. This might happen for a variety of reasons. It might happen in these kind of manmade scenarios, like giving loans. But even when you're trying to classify, this is happening around us. Every example can be traced to COVID, but right now we see that, right? So there are lots of situations where we have to realize that different people with the same bit different symptoms. So conversely, two\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"against some unknown data. So, one other strategy where you don't want to, I mean, one of the other disadvantages of doing this is that maybe that there are some minority anomalies in this data, and the choice of test data that you have made might have hidden all these anomalies, so you never see them, and maybe it's important to see them. So there may be many situations, or maybe you just don't have enough data as a whole to build a good model by only looking at 80%. So another strategy is to systematically do this with different subsets. So what you're really asking at some higher level is that machine learning approach. So, remember, we have seen only decision trees, but we are going to see many models. So there are clearly many ways to build models. And the reason, whenever you see that there are many ways to do something, it's only because there is no guarantee that a given way is the best one. So more or less what you want to validate is, I have, say, seven different strategies\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"the width not equal to 1.8. Among the blue flowers, we are eliminating the. We know there is one which is 1.8 and that will get eliminated. Among the green flowers. It's possible that there is something which is 1.8, but because y is equal to two, it will get retaked all the blue flowers which have 1.8, but I believe there's only one in the data set. So suppose instead of the point that we removed in this time, if we removed a different point, would we get a different decision tree? For that, it's not necessary. You will get a decision tree. It's different. But in general, the removing and modifying the data set in a very small way can produce it. So it's not guaranteed. It will produce. So you can experiment with it. So you could, for instance, in the same data set, probably that's a good experiment for you to use, which is that. Notice that we have two types of discrepancies here, right? So we have this horizontal line and we have this one blue thing which is above the horizontal.\", metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"these values in that example. So unless you specify that, you cannot say that this is unlikely to be true or this is likely to be true, because it will be specific to the interpretation. But the problem now, we have now reduced it to one which is uninterpreted. We are just talking about abstract items. So there was a question in the chat about dimensionality reduction connected to PCA. So, yes, the PCA will be one part of it, but there are also other things that we will see. Sir, I have a question. Yeah. When we model this problem in this way, we didn't capture the frequency of items in a transaction. We were just looking at whether or not that item is present or not. Yeah, but I think for most of these examples, whether someone's buying from a shop or whether it's words in a document, that frequency will be a part of it. Right. Which we are not capturing here. Yeah. So usually this is how mathematical models work. You start with the most basic model, and then you add any features\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"an algorithmic problem. It's not technically a learning problem, because this is a fixed problem once we fix these quantities. So given the set of items and the transactions, and given these two thresholds, find every x y which satisfies these two constraints. This is what we are trying to do. So we will see what it means for learning at the end. Sir, I had a question. So therefore, what we said is that a rule is interesting only if this ratio is bigger than sigma. Right? The fraction of transactions where we see the target of the rule must be at least sigma. If I take m to the other side, this is same as saying there's a number of transactions with x and Y. So this is just the number of transactions. X and y exceeds sigma times the total. It's some whatever, 1% of the total, 10% of the total, and so on. So what we said last time is that this would be our first criteria. So we want to find x union Y, which is plausible. Once we have x union Y, which is plausible, we will try to break\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content=\"we have to realize that different people with the same bit different symptoms. So conversely, two people with the same symptoms don't necessarily. So there are asymptomatic COVID patients. There are people who have a sore throat and a cold and a headache who don't necessarily have COVID. So I cannot just say that if you have these symptoms, you must have COVID, and if you don't have these symptoms, you cannot have COVID. Right. So clearly there is something going on in the background, and that background in our case is revealed through a test. Even tests have errors and all that. So it's really a problem that we have to grapple with in real life. And we will just assume for now that when we reach such a situation, we just take a majority decision. But realistically, if we get too many of these situations, and it's very difficult to decide, we have to ask whether the data has actually been collected correctly. So as we said, the main issue is really how to ask the questions and what\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"the only question you need to ask is, say, the passport number of the patient, and then you will be able to predict whether they have a disease or not, which is totally nonsensical. Right? So the greedy algorithm will say, take it, but from an interpretation point of view, it's a totally useless choice. I'm not saying that this will happen. I'm just saying that if you provide an algorithm in any machine learning situation, you have to be aware of the fact that this algorithm is going to be applied in general blindly to the data. So it has to be driven by the data. So if the data can produce some peculiar behavior, you have to be able to tailor your algorithm to take care of this peculiar behavior. The question is, how would we adapt our algorithm to fix this? So right now, our tree building algorithm blindly picks the attribute that maximizes the information gain. So we need to somehow penalize those attributes which have a wide number of possibilities. Now this is also intuitively\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"natural. So this is a generic problem with this kind of tree model, that it is very sensitive to perturbations in the data. We will look at a more familiar problem, which you are generally aware of called regression. Right? So in regression, what do we do? We take a bunch of points, we try to fit a line to it. Now, if I take one point in that set and remove it, or if I shift it a little bit, the line will perhaps change, but it will change in a very minor way, right? The slope will change slightly. So small changes in input produce small changes in output. So that is a kind of stable kind of situation. So this is something called variance. So how much variance is there in your model? So, variance is basically a property which says, is it the case? So if you have low variance, then small changes in input produce small changes in output. But decision tree, by definition, is a kind of discrete kind of thing. There's no way to slightly change a tree. You change a question and the tree\", metadata={'source': 'audio_5.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_transformers import (\n",
        "    LongContextReorder,\n",
        ")\n",
        "reordering = LongContextReorder()\n",
        "reordered_docs = reordering.transform_documents(docs)\n",
        "\n",
        "# Confirm that the 4 relevant documents are at beginning and end.\n",
        "reordered_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wkO1WQ_64kI",
        "outputId": "e4b3ef5b-51c4-4363-f54a-6ea0fb462f04"
      },
      "id": "4wkO1WQ_64kI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"entered by somebody and then converted to electronic forms. So that would be, there would be two levels of potential sources for errors. The person writing down the information and then the person typing in the information. Now, gradually these kind of electronic forms are spilled in directly, so at least the source of the error is reduced to one step. But still, people mistype things. I mean, there are any number of situations where people type their email address wrong and so notifications don't reach them and so on. So there is this data collection. How do you collect the data and how do you clean it? And the third thing is, how do you make it uniform? So when data is being collected by different people, they may collect different things. And for instance, if you look at the government, typically the government collects data in different forms. For instance, there is a public distribution system which the ration shops, so they collect some information about who is collecting ration\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content='been collected correctly. So as we said, the main issue is really how to ask the questions and what this means. Sorry, sir, I have a question. Yeah. Sir, once we know that the data is young, we are making a prediction and it come out that young. So like other attribute is not relevant other than it has job or not, and then we are not going to look at other attributes. Yeah, but remember that which attributes to look like vary from one path to another. So maybe in this case, right, so what we are saying is that if they are young, we only need the job, right? But if they are middle aged, we need to know the house. So for different combinations, so they may not occur together. I agree, in any decision, but each of these plays a role somewhere. Now, if there is another attribute which never plays a role, as we will see the next tree as that example. Right? So if you look at this, this is a different tree for the same data set. So instead of first asking the age, we ask whether you own a', metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content='It asks one vertical question and one horizontal question and isolates that. Similarly, there is a blue point in the middle here, right there on the right hand side, you can see where my cursor is, that blue part. So here it basically create just to pull that blue point out. So this is, again, kind of an experimental or empirical justification of the argument that smaller trees will give you more manageable and more understandable marks. The tree on the right sort of makes mistakes, but you can kind of figure out why it is drawing the lines where they are. And there are going to be a few anomalies with it. The left hand side is arguably got fewer anomalies, but it has created these strange islands of yellow at the bottom and the spike of green in the middle and all that, which may not make much sense. So this is as far as constraining the thing. Now, if I take this. So now we go back to our, this iris data set. So iris data set had capital X as the input. That was our original input.', metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"can measure it, but you cannot. In some sense, if you could validate it, then this whole problem becomes much simpler. But the whole difficulty with machine learning is exactly this, that there is no sensible way to predict the behavior or even when it will fail. Even if you could say that this is likely to work well here and not likely to work well there that itself would be a huge improvement, not even necessarily a very precise quantification, but just some indication. But all these are very speculative. So that's a huge challenge. So there are some theoretical things you can say which we may not, may or may not get to in this course. But it's a big problem. This is the so called generalization problem. So that's what basically, if you build association rules, is it going to hold or not? I don't know. Okay, sir, I had a question. We have been talking about items and transactions, but we haven't anywhere spoken about whether one customer, suppose if you're talking about somebody\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content=\"against some unknown data. So, one other strategy where you don't want to, I mean, one of the other disadvantages of doing this is that maybe that there are some minority anomalies in this data, and the choice of test data that you have made might have hidden all these anomalies, so you never see them, and maybe it's important to see them. So there may be many situations, or maybe you just don't have enough data as a whole to build a good model by only looking at 80%. So another strategy is to systematically do this with different subsets. So what you're really asking at some higher level is that machine learning approach. So, remember, we have seen only decision trees, but we are going to see many models. So there are clearly many ways to build models. And the reason, whenever you see that there are many ways to do something, it's only because there is no guarantee that a given way is the best one. So more or less what you want to validate is, I have, say, seven different strategies\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"these values in that example. So unless you specify that, you cannot say that this is unlikely to be true or this is likely to be true, because it will be specific to the interpretation. But the problem now, we have now reduced it to one which is uninterpreted. We are just talking about abstract items. So there was a question in the chat about dimensionality reduction connected to PCA. So, yes, the PCA will be one part of it, but there are also other things that we will see. Sir, I have a question. Yeah. When we model this problem in this way, we didn't capture the frequency of items in a transaction. We were just looking at whether or not that item is present or not. Yeah, but I think for most of these examples, whether someone's buying from a shop or whether it's words in a document, that frequency will be a part of it. Right. Which we are not capturing here. Yeah. So usually this is how mathematical models work. You start with the most basic model, and then you add any features\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"we have to realize that different people with the same bit different symptoms. So conversely, two people with the same symptoms don't necessarily. So there are asymptomatic COVID patients. There are people who have a sore throat and a cold and a headache who don't necessarily have COVID. So I cannot just say that if you have these symptoms, you must have COVID, and if you don't have these symptoms, you cannot have COVID. Right. So clearly there is something going on in the background, and that background in our case is revealed through a test. Even tests have errors and all that. So it's really a problem that we have to grapple with in real life. And we will just assume for now that when we reach such a situation, we just take a majority decision. But realistically, if we get too many of these situations, and it's very difficult to decide, we have to ask whether the data has actually been collected correctly. So as we said, the main issue is really how to ask the questions and what\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"natural. So this is a generic problem with this kind of tree model, that it is very sensitive to perturbations in the data. We will look at a more familiar problem, which you are generally aware of called regression. Right? So in regression, what do we do? We take a bunch of points, we try to fit a line to it. Now, if I take one point in that set and remove it, or if I shift it a little bit, the line will perhaps change, but it will change in a very minor way, right? The slope will change slightly. So small changes in input produce small changes in output. So that is a kind of stable kind of situation. So this is something called variance. So how much variance is there in your model? So, variance is basically a property which says, is it the case? So if you have low variance, then small changes in input produce small changes in output. But decision tree, by definition, is a kind of discrete kind of thing. There's no way to slightly change a tree. You change a question and the tree\", metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"the only question you need to ask is, say, the passport number of the patient, and then you will be able to predict whether they have a disease or not, which is totally nonsensical. Right? So the greedy algorithm will say, take it, but from an interpretation point of view, it's a totally useless choice. I'm not saying that this will happen. I'm just saying that if you provide an algorithm in any machine learning situation, you have to be aware of the fact that this algorithm is going to be applied in general blindly to the data. So it has to be driven by the data. So if the data can produce some peculiar behavior, you have to be able to tailor your algorithm to take care of this peculiar behavior. The question is, how would we adapt our algorithm to fix this? So right now, our tree building algorithm blindly picks the attribute that maximizes the information gain. So we need to somehow penalize those attributes which have a wide number of possibilities. Now this is also intuitively\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"an algorithmic problem. It's not technically a learning problem, because this is a fixed problem once we fix these quantities. So given the set of items and the transactions, and given these two thresholds, find every x y which satisfies these two constraints. This is what we are trying to do. So we will see what it means for learning at the end. Sir, I had a question. So therefore, what we said is that a rule is interesting only if this ratio is bigger than sigma. Right? The fraction of transactions where we see the target of the rule must be at least sigma. If I take m to the other side, this is same as saying there's a number of transactions with x and Y. So this is just the number of transactions. X and y exceeds sigma times the total. It's some whatever, 1% of the total, 10% of the total, and so on. So what we said last time is that this would be our first criteria. So we want to find x union Y, which is plausible. Once we have x union Y, which is plausible, we will try to break\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content=\"the width not equal to 1.8. Among the blue flowers, we are eliminating the. We know there is one which is 1.8 and that will get eliminated. Among the green flowers. It's possible that there is something which is 1.8, but because y is equal to two, it will get retaked all the blue flowers which have 1.8, but I believe there's only one in the data set. So suppose instead of the point that we removed in this time, if we removed a different point, would we get a different decision tree? For that, it's not necessary. You will get a decision tree. It's different. But in general, the removing and modifying the data set in a very small way can produce it. So it's not guaranteed. It will produce. So you can experiment with it. So you could, for instance, in the same data set, probably that's a good experiment for you to use, which is that. Notice that we have two types of discrepancies here, right? So we have this horizontal line and we have this one blue thing which is above the horizontal.\", metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"and these subtables be destroyed. And when you stop, you ask whether it's uniform or whether there's a majority. So this is what we were discussing. So a non uniform leaf node where I have run out of questions, but I have different classes. So basically I have identical combination of attributes, but different classes is something which indicates that our data is somehow incomplete. The attributes are not capturing all the criteria which are actually used for the classification. There are some hidden attributes which are not being captured, and this happens quite often. So we can't derive this. This might happen for a variety of reasons. It might happen in these kind of manmade scenarios, like giving loans. But even when you're trying to classify, this is happening around us. Every example can be traced to COVID, but right now we see that, right? So there are lots of situations where we have to realize that different people with the same bit different symptoms. So conversely, two\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"of elearning platforms, there's a lot of emphasis on trying to structure topics in such a way that students who find difficulty, you can identify why they are facing difficulties. So you want to think of these concepts that you're teaching as these items. And basket is now a set of concepts. And if you look at a concept which is difficult to learn, maybe there is a connection to another concept which is also difficult to learn. So you might want to group this. So people who misunderstand a also misunderstand b. And therefore maybe the problems has to start by fixing b. And another place where this is used is in kind of similarities of documents. So if two documents share words, then you can think they are similar. So you can think of documents. Or if two words appear rather in many documents, you can think they are similar. So if you say that wherever x appears, y also appears, then it may mean that x and y are actually related concepts. So this is the context. So the real question is\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"picked up is because we have not interpreted. So you might ask, okay, why passport number? But it could be something indirect, like, it could be some kind of an encoded timestamp. It could be some actions which are recorded in some system, and then one of the columns records somehow the timestamp, and no two events happen with the same timestamp. So there could be any number of hidden reasons why something is actually unique. And either you have to clean up the data and check it, or you have to build a safeguard against this happening. It may or may not happen, but I just wanted to bring this up because this is a byproduct of the algorithm that we have now. It's a shortcoming. It's a shortcoming in the sense that if we apply the algorithm that we have now, right now, in such a situation, blindly, then we will end up with this kind of curious choice right up front. It will tell us that the only question you need to ask is, say, the passport number of the patient, and then you will be\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"have to, in the example that you gave, you would have to first separate out the data for these, say, the people who buy one month groceries at a time from those who buy at more frequent intervals and then analyze them separately, because together the data doesn't actually make sense. So last time, if you remember, I talked about this unsupervised. So maybe one thing that you need to do when you have something large is to basically look at the transactions and categorize them according to some criteria, maybe by the size of the basket. And then you will find that there are maybe a lot of people who buy five items at a time. There are people who buy ten to 20 items at a time. There are people who buy 40 items at a time. And maybe you need to then apply the model separately to each of these clusters. So all of these things are not a one size fits all solution. And also, it's not that one approach on its own is going to solve the problem at any given time. So you need to have a kind of\", metadata={'source': 'audio_2.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_2=\" What are the advantages of the Apriori algorithm?\"\n"
      ],
      "metadata": {
        "id": "gVin1CH17aMB"
      },
      "id": "gVin1CH17aMB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = lotr.get_relevant_documents(query_2)\n",
        "docs"
      ],
      "metadata": {
        "id": "OxUgDKKa7mCX",
        "outputId": "1892d6ea-cbae-4704-9987-02d85ec9215e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "OxUgDKKa7mCX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"yet, first of all, a truly learning problem. It's more an algorithmic problem, but still, it's an interesting problem nonetheless, because I just want to illustrate how it affects the way in which we calculate what might be trivial with small data becomes nontrivial with large data. So this is the problem. So given a set of items, capital n, which is large, and a, given a set of transactions m, which is again large, and given these two ratios between zero and one, find every pair x and y such that x implies y is a valid association. So we can break up this thing into two steps. I mean, we want to first check whether x implies y is worth looking at at all. So we first look at the support part. We want to know whether x, sorry, yeah, we want to know whether the count divided by m is bigger than the support, which is the same as taking this m to the other side and saying whether the count is bigger than a certain fraction of the total. So the first idea is to identify those sets whose\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"frequency? These are discussed in that book where I have given you the reference for the first lecture and for this lecture, so you can read about it. It's not particularly relevant to the work that we want to focus on in this course, so I won't get into it in any detail, but there is a very accessible introduction to that, in that chapter later on. So you can look at it and see a lot of it is some kind of heuristics, but you can look at it. So I'll stop with this. Any questions? Is there any way to predict how better our association rule is? So that is a general problem that we will come across. There is no real good way to predict how good it is. You can, of course, associate with a concrete data set how reliable it is for that data set. But this is going to be one of the challenges, as we will see going along, which is that you are always building rules or any model with respect to a fixed data set, and you are going to apply it to some other data set which you have not seen. So\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content='So we were looking at this market basket analysis, and towards the end of the discussion on association rule rules, if everybody who buys X is also likely to buy y. We said that one application of this association rule idea is to have these so called class association rules. So the right hand side was a category. We looked at an example with documents and we said, if a document has these words, it is also likely to belong to this category. So that brings us to the topic that is one of the central ones in machine learning, which is the idea of supervised learning. So in supervised learning, we have a set of items, and each item belongs to some category or class, and we distinguish these items in terms of some attributes. So you can think about this, as we will see shortly, you can think about these attributes as columns, right? So the attributes will be things like name, age, date of birth, whatever, income, stuff like that. So each row in the table will be one item, and there will be a', metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"against some unknown data. So, one other strategy where you don't want to, I mean, one of the other disadvantages of doing this is that maybe that there are some minority anomalies in this data, and the choice of test data that you have made might have hidden all these anomalies, so you never see them, and maybe it's important to see them. So there may be many situations, or maybe you just don't have enough data as a whole to build a good model by only looking at 80%. So another strategy is to systematically do this with different subsets. So what you're really asking at some higher level is that machine learning approach. So, remember, we have seen only decision trees, but we are going to see many models. So there are clearly many ways to build models. And the reason, whenever you see that there are many ways to do something, it's only because there is no guarantee that a given way is the best one. So more or less what you want to validate is, I have, say, seven different strategies\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"okay, maybe it is not really that any question about this. Okay, so now one of the problems with decision trees, which you will see later on, is also that a lot of the construction of the tree depends on these statistics. Because we said that we look at which attribute has the maximum discrepancy, whether it's entropy or genie index or whatever, which one of them will improve it the most. And that improvement, or lack of improvement really depends on the distribution of the different inputs at that point in my table. So if there is a borderline case, it could be that by shifting one value here or there, the attribute which has the highest improvement might shift from one to the other. And then I ask a different question. The moment I ask a different question, the tree becomes radically different because the question pattern changes and the split will change and so on. So here is to illustrate that what they have done is they have first, so y equal to one. Remember that the categories\", metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"the order, sometimes we don't. Addresses, of course, are written in a million different ways. So there are all kinds of issues with just getting the data to a format where you can work on it. So this is an entirely different ballgame. It's much more kind of. There are lots of tools and techniques to deal with this, but that's not really going to be the focus of the course. So, in a sense, if you want to think about it, this data mining aspect will be almost missing from this course, even though it's part of the title. So what we are really going to look at is the machine learning aspect. So learning means you are trying to understand something that you don't know before. And machine learning suggests that it's done automatically. It's done by now machine as a computer. So there is an algorithm which learns something about, again, it's always with respect to data. So it's something about the data. So what we are trying to do is learn some kind of mathematical models from data. And this\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"what you're really looking for is correlations between sets of items across transactions, which we formalize in terms of these association groups. X implies y. And what we saw is that as such, combinatorially, this is a very complicated thing to calculate, given the sizes of the sets involved. But we can use this appropriate principle both to identify the sets which are interesting, those which are frequent enough to be considered, and also to decompose them into rules. So you use the approoriate twice, once to find the frequent z, and second to decompose each frequent z into possible x implies y. And using this, we can build our first simple supervised learning model. So these rules now become a very simple way of prediction. Now, if you give me a document, I will look at what words are there in the document in this previous example. And if it contains the word student and school, I will predict education. If it contains game and team, I'll predict sports. Now, of course, if it has\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content=\"it. So you could basically just take the majority, right? So supposing you do all this and you come to a situation where you have eight customers who have similar attributes, and five of them are given a loan and three are not given, then if you get a new case which looks like this, you will say, okay, five out of eight were given. So let me predict that the new case will be given, because that's a nature. So that's really the only sensible thing you can do in the absence of any other information. So that's typically what a decision three algorithm. So it'll ask question by question. The real we have to figure out is this part, which is how do you pick the next attribute to question. But once you pick an attribute, then the next step is automatic. It will filter out the rows according to the values attribute. And then you have to ask the same algorithm applied on each of those subtables, and these subtables be destroyed. And when you stop, you ask whether it's uniform or whether\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content='have to do a search through all possible trees. So instead we wanted to use some heuristic. So the main question that we have to ask is, which attribute do we query next at any stage. So our goal is to achieve this partition, which is pure, where all the values are yes or all the values are no. So we try to accelerate towards that. So that is this greedy strategy. So we use a heuristic, which will reduce the impurity as much as possible. And when we move from one node to its children by asking a question, what we do is we compute a weighted average. So for each node we can compute the impurity. But then when we combine the children of a node to get the impurity at the next level, we use a weighted average. So going simple weighted average just assigns a weight one to every item. So you just take the fraction. So for node one, you take the fraction of instances in that partition, multiply that fraction by the impurity and so on, and add it up, and we choose the one which reduces. So', metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"at the time of constructing the tree. So this is something that certainly should be what is the, but the main thing I wanted to emphasize is that modulo understanding the parameters and what you can do with it, you actually don't have to do any of the encoding that we discussed in terms of finding the impurity and then maximizing it all that is actually something that is taken care of by the library. So all that discussion that we had about how a decision tree is constructed, choosing the best split for the numerical values, then comparing the impurity gain for all the things, picking the best one and so on, all that is done automatically. So you really never have to implement that. So the reason that it's good to know how all these things work is because indirectly that impacts how these parameters that you are allowed to control will work. So you have to have a little bit of an idea about what's going on behind the algorithm in order to make best use of it when it is not producing\", metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"You can do it in two different ways. So what I am saying is that I'm overlapping the thing, right? So I'm saying for each p, this is what I'm doing for each transaction, for every subset. But now I can basically change this and say for each, because obviously I don't have to look at z, which is not mentioned in this particular transaction. So instead of looking at every possible subset z, I can look for only those subsets which are there in that transaction, because everything else does not get incremented. Now, what you are asking is the other way around. And this is potentially, I mean, superficially, they are the same thing. You have two loops and you are interchanging the order. But this is potentially much more expensive because there will be a lot of items, subsets which never occur. I mean, for instance, you might be looking for subsets where people are buying two items which are totally of different types of categories, and they might never buy these together. Like for\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"its topic is education. And if it has game and team, then it is. So this is a special kind of association rule, where the right hand side of the rule is always a singleton, and it corresponds to a special type of item which is a category, in this case a topic. So when you have a table like this, the rows may have different number of entries. Or if you want to think about it as a table, then some columns may be blank. So not all columns are filled, but there's one last column which is filled. And now you want to now construct these rules corresponding to the first k minus one columns, implying the last column. And this now becomes something where these rules that you get out of this give you a kind of classifier. So this is a kind of a simplistic way of doing supervised learning. So that kind of brings me to the end of this basic treatment of classes, this market basket analysis. So what you're really looking for is correlations between sets of items across transactions, which we\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content=\"one of the things, byproducts of decision tree will be a kind of implicit importance, ranking among the attributes, which ones are more significant. So not all columns are equally important. So these are all things that have come up. So maybe when we come to it later on we'll discuss it. But these questions that you're asking, sir, when we form this decision tree, is it important or in some sense beneficial if we know the data? Insight of the data. Insight of the data, meaning what? As in the relevance of each column? Yes, normally that is, I mean, I cannot say it will always help. Normally it will help. But on the other hand, you have to assume that you do not have. So what you're really asking in a more general setting is that if a person who is kind of aware of the context, who's a specialist or a domain expert in this, so say somebody who has been associated with this, whatever, this bank, this particular bank, which is giving out loans, if they build the tree, they might make\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"is which value are we using to make the greedy choice. So that's the point. Yeah. So I guess linear will be better, even computationally. Right? Well, this kind of computation doesn't take much effort, right? Instead of comparing two values, you're squaring it and adding it. And so arithmetic operations hardly make any. See, log is a more expensive calculation. So that is the point. Take logs of small values. So logs of small values are also painful to calculate. So that's one reason you don't want to take logs. But otherwise, if I'm just doing multiplication and addition, it doesn't really cost much. Okay, so in the case of genie index, we are achieving a stopping criteria much earlier, right? That's the case, yeah. What we are saying here is that we are actually going to, we say that we are going to go until we either use up all the attributes or we reach a uniform class. Now, this is a reasonable thing to do if the number of attributes is small. But if you have a very large number\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"So remember, these x I's are actually not unknowns. These x I's known. So these x I's are what you get. The theta I's are the unknowns that you are trying to figure out. But in terms of the theta I's you can predict for a given xi. If you have computed some theta I's, then the answer is summation theta I x. So therefore the target that we have is clearly to find the best line. So let's assume we have a simple case of only one variable. So we have x one, x two, and so on. So we have n points. In reality, each of these x size is a vector of k, and the y, by convention, is always the label. So in the earlier thing, when we looked at that scikitlearn decision tree thing, we used capital x to denote the input matrix and y to denote the column matrix of output. So this is a normal standard convention in supervised learning that x's denote the inputs of the training data and y denotes the output label. In this case, it's not a label, but it's an output value. So in order to compute the best\", metadata={'source': 'audio_5.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reordered_docs = reordering.transform_documents(docs)\n",
        "\n",
        "# Confirm that the 4 relevant documents are at beginning and end.\n",
        "reordered_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n32e-h4Le5_J",
        "outputId": "63d4225e-3643-440f-8ba0-a74ea7afe53c"
      },
      "id": "n32e-h4Le5_J",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"yet, first of all, a truly learning problem. It's more an algorithmic problem, but still, it's an interesting problem nonetheless, because I just want to illustrate how it affects the way in which we calculate what might be trivial with small data becomes nontrivial with large data. So this is the problem. So given a set of items, capital n, which is large, and a, given a set of transactions m, which is again large, and given these two ratios between zero and one, find every pair x and y such that x implies y is a valid association. So we can break up this thing into two steps. I mean, we want to first check whether x implies y is worth looking at at all. So we first look at the support part. We want to know whether x, sorry, yeah, we want to know whether the count divided by m is bigger than the support, which is the same as taking this m to the other side and saying whether the count is bigger than a certain fraction of the total. So the first idea is to identify those sets whose\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content='So we were looking at this market basket analysis, and towards the end of the discussion on association rule rules, if everybody who buys X is also likely to buy y. We said that one application of this association rule idea is to have these so called class association rules. So the right hand side was a category. We looked at an example with documents and we said, if a document has these words, it is also likely to belong to this category. So that brings us to the topic that is one of the central ones in machine learning, which is the idea of supervised learning. So in supervised learning, we have a set of items, and each item belongs to some category or class, and we distinguish these items in terms of some attributes. So you can think about this, as we will see shortly, you can think about these attributes as columns, right? So the attributes will be things like name, age, date of birth, whatever, income, stuff like that. So each row in the table will be one item, and there will be a', metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"okay, maybe it is not really that any question about this. Okay, so now one of the problems with decision trees, which you will see later on, is also that a lot of the construction of the tree depends on these statistics. Because we said that we look at which attribute has the maximum discrepancy, whether it's entropy or genie index or whatever, which one of them will improve it the most. And that improvement, or lack of improvement really depends on the distribution of the different inputs at that point in my table. So if there is a borderline case, it could be that by shifting one value here or there, the attribute which has the highest improvement might shift from one to the other. And then I ask a different question. The moment I ask a different question, the tree becomes radically different because the question pattern changes and the split will change and so on. So here is to illustrate that what they have done is they have first, so y equal to one. Remember that the categories\", metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"what you're really looking for is correlations between sets of items across transactions, which we formalize in terms of these association groups. X implies y. And what we saw is that as such, combinatorially, this is a very complicated thing to calculate, given the sizes of the sets involved. But we can use this appropriate principle both to identify the sets which are interesting, those which are frequent enough to be considered, and also to decompose them into rules. So you use the approoriate twice, once to find the frequent z, and second to decompose each frequent z into possible x implies y. And using this, we can build our first simple supervised learning model. So these rules now become a very simple way of prediction. Now, if you give me a document, I will look at what words are there in the document in this previous example. And if it contains the word student and school, I will predict education. If it contains game and team, I'll predict sports. Now, of course, if it has\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content='have to do a search through all possible trees. So instead we wanted to use some heuristic. So the main question that we have to ask is, which attribute do we query next at any stage. So our goal is to achieve this partition, which is pure, where all the values are yes or all the values are no. So we try to accelerate towards that. So that is this greedy strategy. So we use a heuristic, which will reduce the impurity as much as possible. And when we move from one node to its children by asking a question, what we do is we compute a weighted average. So for each node we can compute the impurity. But then when we combine the children of a node to get the impurity at the next level, we use a weighted average. So going simple weighted average just assigns a weight one to every item. So you just take the fraction. So for node one, you take the fraction of instances in that partition, multiply that fraction by the impurity and so on, and add it up, and we choose the one which reduces. So', metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"You can do it in two different ways. So what I am saying is that I'm overlapping the thing, right? So I'm saying for each p, this is what I'm doing for each transaction, for every subset. But now I can basically change this and say for each, because obviously I don't have to look at z, which is not mentioned in this particular transaction. So instead of looking at every possible subset z, I can look for only those subsets which are there in that transaction, because everything else does not get incremented. Now, what you are asking is the other way around. And this is potentially, I mean, superficially, they are the same thing. You have two loops and you are interchanging the order. But this is potentially much more expensive because there will be a lot of items, subsets which never occur. I mean, for instance, you might be looking for subsets where people are buying two items which are totally of different types of categories, and they might never buy these together. Like for\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"one of the things, byproducts of decision tree will be a kind of implicit importance, ranking among the attributes, which ones are more significant. So not all columns are equally important. So these are all things that have come up. So maybe when we come to it later on we'll discuss it. But these questions that you're asking, sir, when we form this decision tree, is it important or in some sense beneficial if we know the data? Insight of the data. Insight of the data, meaning what? As in the relevance of each column? Yes, normally that is, I mean, I cannot say it will always help. Normally it will help. But on the other hand, you have to assume that you do not have. So what you're really asking in a more general setting is that if a person who is kind of aware of the context, who's a specialist or a domain expert in this, so say somebody who has been associated with this, whatever, this bank, this particular bank, which is giving out loans, if they build the tree, they might make\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"So remember, these x I's are actually not unknowns. These x I's known. So these x I's are what you get. The theta I's are the unknowns that you are trying to figure out. But in terms of the theta I's you can predict for a given xi. If you have computed some theta I's, then the answer is summation theta I x. So therefore the target that we have is clearly to find the best line. So let's assume we have a simple case of only one variable. So we have x one, x two, and so on. So we have n points. In reality, each of these x size is a vector of k, and the y, by convention, is always the label. So in the earlier thing, when we looked at that scikitlearn decision tree thing, we used capital x to denote the input matrix and y to denote the column matrix of output. So this is a normal standard convention in supervised learning that x's denote the inputs of the training data and y denotes the output label. In this case, it's not a label, but it's an output value. So in order to compute the best\", metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"is which value are we using to make the greedy choice. So that's the point. Yeah. So I guess linear will be better, even computationally. Right? Well, this kind of computation doesn't take much effort, right? Instead of comparing two values, you're squaring it and adding it. And so arithmetic operations hardly make any. See, log is a more expensive calculation. So that is the point. Take logs of small values. So logs of small values are also painful to calculate. So that's one reason you don't want to take logs. But otherwise, if I'm just doing multiplication and addition, it doesn't really cost much. Okay, so in the case of genie index, we are achieving a stopping criteria much earlier, right? That's the case, yeah. What we are saying here is that we are actually going to, we say that we are going to go until we either use up all the attributes or we reach a uniform class. Now, this is a reasonable thing to do if the number of attributes is small. But if you have a very large number\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"its topic is education. And if it has game and team, then it is. So this is a special kind of association rule, where the right hand side of the rule is always a singleton, and it corresponds to a special type of item which is a category, in this case a topic. So when you have a table like this, the rows may have different number of entries. Or if you want to think about it as a table, then some columns may be blank. So not all columns are filled, but there's one last column which is filled. And now you want to now construct these rules corresponding to the first k minus one columns, implying the last column. And this now becomes something where these rules that you get out of this give you a kind of classifier. So this is a kind of a simplistic way of doing supervised learning. So that kind of brings me to the end of this basic treatment of classes, this market basket analysis. So what you're really looking for is correlations between sets of items across transactions, which we\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content=\"at the time of constructing the tree. So this is something that certainly should be what is the, but the main thing I wanted to emphasize is that modulo understanding the parameters and what you can do with it, you actually don't have to do any of the encoding that we discussed in terms of finding the impurity and then maximizing it all that is actually something that is taken care of by the library. So all that discussion that we had about how a decision tree is constructed, choosing the best split for the numerical values, then comparing the impurity gain for all the things, picking the best one and so on, all that is done automatically. So you really never have to implement that. So the reason that it's good to know how all these things work is because indirectly that impacts how these parameters that you are allowed to control will work. So you have to have a little bit of an idea about what's going on behind the algorithm in order to make best use of it when it is not producing\", metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"it. So you could basically just take the majority, right? So supposing you do all this and you come to a situation where you have eight customers who have similar attributes, and five of them are given a loan and three are not given, then if you get a new case which looks like this, you will say, okay, five out of eight were given. So let me predict that the new case will be given, because that's a nature. So that's really the only sensible thing you can do in the absence of any other information. So that's typically what a decision three algorithm. So it'll ask question by question. The real we have to figure out is this part, which is how do you pick the next attribute to question. But once you pick an attribute, then the next step is automatic. It will filter out the rows according to the values attribute. And then you have to ask the same algorithm applied on each of those subtables, and these subtables be destroyed. And when you stop, you ask whether it's uniform or whether\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"the order, sometimes we don't. Addresses, of course, are written in a million different ways. So there are all kinds of issues with just getting the data to a format where you can work on it. So this is an entirely different ballgame. It's much more kind of. There are lots of tools and techniques to deal with this, but that's not really going to be the focus of the course. So, in a sense, if you want to think about it, this data mining aspect will be almost missing from this course, even though it's part of the title. So what we are really going to look at is the machine learning aspect. So learning means you are trying to understand something that you don't know before. And machine learning suggests that it's done automatically. It's done by now machine as a computer. So there is an algorithm which learns something about, again, it's always with respect to data. So it's something about the data. So what we are trying to do is learn some kind of mathematical models from data. And this\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"against some unknown data. So, one other strategy where you don't want to, I mean, one of the other disadvantages of doing this is that maybe that there are some minority anomalies in this data, and the choice of test data that you have made might have hidden all these anomalies, so you never see them, and maybe it's important to see them. So there may be many situations, or maybe you just don't have enough data as a whole to build a good model by only looking at 80%. So another strategy is to systematically do this with different subsets. So what you're really asking at some higher level is that machine learning approach. So, remember, we have seen only decision trees, but we are going to see many models. So there are clearly many ways to build models. And the reason, whenever you see that there are many ways to do something, it's only because there is no guarantee that a given way is the best one. So more or less what you want to validate is, I have, say, seven different strategies\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"frequency? These are discussed in that book where I have given you the reference for the first lecture and for this lecture, so you can read about it. It's not particularly relevant to the work that we want to focus on in this course, so I won't get into it in any detail, but there is a very accessible introduction to that, in that chapter later on. So you can look at it and see a lot of it is some kind of heuristics, but you can look at it. So I'll stop with this. Any questions? Is there any way to predict how better our association rule is? So that is a general problem that we will come across. There is no real good way to predict how good it is. You can, of course, associate with a concrete data set how reliable it is for that data set. But this is going to be one of the challenges, as we will see going along, which is that you are always building rules or any model with respect to a fixed data set, and you are going to apply it to some other data set which you have not seen. So\", metadata={'source': 'audio_2.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_3=\" What distinguishes training data in supervised learning, and what is its purpose? \""
      ],
      "metadata": {
        "id": "Ej1ZXYLvfHVT"
      },
      "id": "Ej1ZXYLvfHVT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = lotr.get_relevant_documents(query_3)\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAwH5DWcfltS",
        "outputId": "f26dcec8-e680-4c2d-bb86-eb9e807e20f2"
      },
      "id": "kAwH5DWcfltS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"a specification, but generating a concrete program from a generic program you can think of a model template as. So I just give you a line here which says a Y equal to Mx plus c. And here I want a specific m zero and C zero, which fits the given data in the best possible way, which is also part of the description of the algorithm. What does it mean for one line to be better than another line? So that's part of it. So the other side of this picture, as I mentioned, is when you don't have this training data, you don't have any examples that people have already labeled, but you are looking for some kind of patterns. So there is no guidance. So the thing about supervised learning is somebody should have gone through and given you this information before. Now, this information could have been collected over time. Maybe it's not manually collected, like the school marks. The school marks over time. Everybody has. I mean, the school keeps a record of what happens in the model exams, what\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"a fixed data set, and you are going to apply it to some other data set which you have not seen. So will that generalize well or not is the biggest question in machine learning. How do you know that the training data that you have used to build your model is actually representative of the data that you see in the real. And there could be many reasons why it is not valid. It could be because of sampling. So, for instance, you might be building a model for some consumer behavior by looking at one segment of. Maybe you are looking at the behavior of people who are in their, are building a model of how people behave, but your actual market consists of people who are maybe in their 40s, who have a very different way of dealing with things. So you need to be careful that the data that you're looking at is actually representative. So this is a huge problem and there's no correct answer. You can measure it, but you cannot. In some sense, if you could validate it, then this whole problem\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content='whatever, income, stuff like that. So each row in the table will be one item, and there will be a special column which indicates what category, depending on the classification problem that we are dealing with, what category it is. And the goal of supervised learning is to now construct, given a new row, a new item, a new combination of these attributes, which is not seen before, try to predict what would be the most appropriate category to assign. So these items which are given with the labels. So these are called labels. So these items are called training data. So we have labeled training data, which consists of some information which has been collected in the past, some historical information about items and their classification. And we want to find a model that generalizes the training data. So since normally this categorization corresponds to some kind of classification, this is typically called a classification problem. So classification problem could be a binary problem. It', metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"particular distribution, I should keep a similar ratio. So this is called stratified sampling. But these are sort of different things. But the good thing for us is that in the libraries that we will use, this is an automatic step. You just have to say, split the data into train and test, and it'll do. So, training set and test set. That's it. So this is a little bit, what should I say? Confusing, because we actually call the whole thing also training, and then we split it. And then we again call this training and test. Right? So training data is a little bit of an ambiguous term. So training data is both the entire data set that you are given to start with. And then it is the specific choice that you make about how to split this data into a large part, which you will use for building the model, and a small part that you will reserve for validating the model. So depending on how much data you have, the usual practice is about 20% to 30% of it you keep aside. So you use about 70% to 80%\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"and that is this. So this blue flower here where you can see the cursor just at this corner here where I'm rotating the cursor. So this has width 1.8. So that's what we're identifying. We're identifying among the training data. So the training data where y is equal to one, where the label class label was one among those points, which is the one where the second column of the input, the width is maximum. Right? So now what you do is you basically remove it. So you say that I want a training set in which I don't have 1.8, so I have either class is equal to two, y is equal to two, or I don't have 1.8. So basically this has all the inputs except that one. If there were more than one, all the ones which are of class one and 1.8 get eliminated. So I'm basically effectively removing this one data point from my training set. Understand what I'm doing? So I'm taking the old training set of 150 flowers, and I'm removing this one tree by identifying which is the widest. So remember that last\", metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"the data. So what we are trying to do is learn some kind of mathematical models from data. And this falls into two broad categories. So the first category is where you are given examples. So you are told, for instance, this is, for example, supposing you're trying to evaluate whether a painting is painted by a particular type of. So there are these pools of painting, like impressionists and cubists and so on. So you might be given a lot of pictures saying, this is cubist, this is not cubist, this is impressionist, and so on. And then from these examples which are given to you with manual information, you are supposed to build a model which will take an unknown painting and tell you from its features which of these categories. So this is a typical supervised learning kind of thing. Unsupervised learning is something which is closer to the data mining situation where you have data and you are looking for patterns, but you don't really have a clear idea beforehand what patterns they are.\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"a slightly different presentation of the idea. Okay, so now, as I said, this whole thing so far has been largely a kind of algorithmic problem, right? In some sense, if I fix the set of items and the set of transactions and the set of the two thresholds, the support and the confidence threshold, then for any x, comma y, either it is true or it is not true. So there is a fixed answer. So the answer is known. So this is something where I can actually validate that you have either enumerated all the association rules or you have missed out something. So technically there is no learning involved. It's more an algorithmic question. So how does one connect this to learning? Well, in specific context, you can interpret these rules as classification rules. So, remember we said supervised learning says, if this is there, then it is a fraud. If this thing is not there, then it is not a fraud, and so on. So, let's look at a typical example. So, supposing we have some question which is about\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content=\"base our model on should be somehow indicative of what we are going to predict. If we are going to take data pertaining to one group of individuals and extrapolate it to a completely different profile of individuals, then it's unlikely that this model that we built has any relevance. So there is this fundamental assumption. So we are not going to make this assumption mathematically precise in this course. So, in the advanced machine learning course, we will talk about a kind of theory of learning in which you can make this thing rigorous. But we are going to assume that there is a correlation between the distribution of training examples and the distribution of unseen data. So these are probabilistic, of course. Even if you have a similar set of data, you could draw samples which omit a few cases and have a few other cases. So it's always going to be a kind of probabilistic argument. But what you're saying is that this is a representative sample. So you're not saying that the examples\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"classification model is that this correct answer is not known. I mean, if we knew the answer, if we knew a better way to come up with the correct answer, we would not build this model. So the reason we are building this model is we don't have a reliable way to compute the correct answer. So in this situation, when we do not have a reference value to compare our answers with, how do we measure whether or not our model is a good one? So on what basis can we evaluate? So what we need is a comparison where we know the answers. But the only situation where we know the answers is our training data. Our training data comes to us with labels. So for each input in our training data, we know the manually or however classified correct answer. So we are assuming those are the correct answers because otherwise our model building process will not make sense. So assuming that those are correct answers, we are building our model. So that's the only source of inputs and outputs where we know the\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"So remember, these x I's are actually not unknowns. These x I's known. So these x I's are what you get. The theta I's are the unknowns that you are trying to figure out. But in terms of the theta I's you can predict for a given xi. If you have computed some theta I's, then the answer is summation theta I x. So therefore the target that we have is clearly to find the best line. So let's assume we have a simple case of only one variable. So we have x one, x two, and so on. So we have n points. In reality, each of these x size is a vector of k, and the y, by convention, is always the label. So in the earlier thing, when we looked at that scikitlearn decision tree thing, we used capital x to denote the input matrix and y to denote the column matrix of output. So this is a normal standard convention in supervised learning that x's denote the inputs of the training data and y denotes the output label. In this case, it's not a label, but it's an output value. So in order to compute the best\", metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"time. Everybody has. I mean, the school keeps a record of what happens in the model exams, what happens in the board exam. So it comes automatically. The bank will be keeping records of all the loans that it bought and what happened to the customers who bought loans. So this historical information is accumulated over time. On the other hand, in some situations, like the example I mentioned about classifying paintings, now, when you go into a museum or you go into some art gallery or something, the painting doesn't have a label on it, saying, this is a painting of this type and this is a painting of that type. So somebody, if you want to fit this training model to it, somebody has to sit and actually label these things for the algorithm. So there is a lot of work in it. So generating a lot of valid training data is itself a kind of computationally intensive task. How do you provide a lot of well trained examples? Because the assumption is that the labels that these training samples\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"its topic is education. And if it has game and team, then it is. So this is a special kind of association rule, where the right hand side of the rule is always a singleton, and it corresponds to a special type of item which is a category, in this case a topic. So when you have a table like this, the rows may have different number of entries. Or if you want to think about it as a table, then some columns may be blank. So not all columns are filled, but there's one last column which is filled. And now you want to now construct these rules corresponding to the first k minus one columns, implying the last column. And this now becomes something where these rules that you get out of this give you a kind of classifier. So this is a kind of a simplistic way of doing supervised learning. So that kind of brings me to the end of this basic treatment of classes, this market basket analysis. So what you're really looking for is correlations between sets of items across transactions, which we\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content=\"a dog picture from a cat picture, or one which is neither of the two, it's not very easy to quantify that. And there the attributes in a picture are typically just if you think of a picture as a digital picture, it's a bunch of pixels and their colors and their arrangement, their relative arrangement. So even I'm saying, even if you have some domain knowledge, it's not very clear that the person's domain knowledge is aligned to the way the data is available. So what we are going to be doing is agnostic to the domain. So we are not going to believe anything or assume anything about the domain, except that we will want to validate at the end somehow that what we are doing is right. But in practice what you're saying makes sense that really to do supervised learning, it's much more realistic to do it in collaboration with somebody who understands a domain rather than just doing it blindly. Because also when you do it blindly, you might come up with solutions which make no sense. You\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"gain by the scattering of that attribute. So if we have high gain divided by high scattering, then the net normalized effect is lower. So you might choose an attribute which actually gives you a lower information gain overall, because the attribute itself is less static. And that's the thing that we want to achieve. Just to emphasize that when you have a machine learning algorithm, see generally, what is a machine learning algorithm doing? It's trying to describe the shape of the model based on the training data. So in this case it's literally the shape, because you have many possible trees you could construct, and the actual tree you construct depends on the data. And because you don't have any preconceptions about the data, you have to make sure that if there are these kind of patterns which disturb your algorithm, you will be able to counteract. So that's the purpose of this information gain ratio. It's not just the information gain alone, which is what we had initially. It's\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"to show you some code before we come back to theory. So, is there any further questions? So, at the moment, I'm not expecting you to do anything with this code other than to understand that a, it is relatively painless to invoke a model in scikitlearn. And if you have this kind of visualization code, either you write it yourself or somebody gives it to you. You can then interpret your models visually and then experiment with it by changing things and seeing what happens. And that gives you a fair amount of insight both into your data and into how the model is working. So it gives you some indications about the limitations of that particular. Okay, so now I'm going to do something hopefully not unfamiliar to you. Right? At the beginning, when we talked about supervised learning, we said that we are trying to predict something, and those predictions can be in two types. So one type is what we have seen in the decision tree, which is a classification. So the predicted value is one from a\", metadata={'source': 'audio_5.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reordered_docs = reordering.transform_documents(docs)\n",
        "\n",
        "# Confirm that the 4 relevant documents are at beginning and end.\n",
        "reordered_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YLl3Va0DfsI_",
        "outputId": "a492f588-704b-4084-aa72-034ed0a56ba4"
      },
      "id": "YLl3Va0DfsI_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"a specification, but generating a concrete program from a generic program you can think of a model template as. So I just give you a line here which says a Y equal to Mx plus c. And here I want a specific m zero and C zero, which fits the given data in the best possible way, which is also part of the description of the algorithm. What does it mean for one line to be better than another line? So that's part of it. So the other side of this picture, as I mentioned, is when you don't have this training data, you don't have any examples that people have already labeled, but you are looking for some kind of patterns. So there is no guidance. So the thing about supervised learning is somebody should have gone through and given you this information before. Now, this information could have been collected over time. Maybe it's not manually collected, like the school marks. The school marks over time. Everybody has. I mean, the school keeps a record of what happens in the model exams, what\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content='whatever, income, stuff like that. So each row in the table will be one item, and there will be a special column which indicates what category, depending on the classification problem that we are dealing with, what category it is. And the goal of supervised learning is to now construct, given a new row, a new item, a new combination of these attributes, which is not seen before, try to predict what would be the most appropriate category to assign. So these items which are given with the labels. So these are called labels. So these items are called training data. So we have labeled training data, which consists of some information which has been collected in the past, some historical information about items and their classification. And we want to find a model that generalizes the training data. So since normally this categorization corresponds to some kind of classification, this is typically called a classification problem. So classification problem could be a binary problem. It', metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"and that is this. So this blue flower here where you can see the cursor just at this corner here where I'm rotating the cursor. So this has width 1.8. So that's what we're identifying. We're identifying among the training data. So the training data where y is equal to one, where the label class label was one among those points, which is the one where the second column of the input, the width is maximum. Right? So now what you do is you basically remove it. So you say that I want a training set in which I don't have 1.8, so I have either class is equal to two, y is equal to two, or I don't have 1.8. So basically this has all the inputs except that one. If there were more than one, all the ones which are of class one and 1.8 get eliminated. So I'm basically effectively removing this one data point from my training set. Understand what I'm doing? So I'm taking the old training set of 150 flowers, and I'm removing this one tree by identifying which is the widest. So remember that last\", metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"a slightly different presentation of the idea. Okay, so now, as I said, this whole thing so far has been largely a kind of algorithmic problem, right? In some sense, if I fix the set of items and the set of transactions and the set of the two thresholds, the support and the confidence threshold, then for any x, comma y, either it is true or it is not true. So there is a fixed answer. So the answer is known. So this is something where I can actually validate that you have either enumerated all the association rules or you have missed out something. So technically there is no learning involved. It's more an algorithmic question. So how does one connect this to learning? Well, in specific context, you can interpret these rules as classification rules. So, remember we said supervised learning says, if this is there, then it is a fraud. If this thing is not there, then it is not a fraud, and so on. So, let's look at a typical example. So, supposing we have some question which is about\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content=\"classification model is that this correct answer is not known. I mean, if we knew the answer, if we knew a better way to come up with the correct answer, we would not build this model. So the reason we are building this model is we don't have a reliable way to compute the correct answer. So in this situation, when we do not have a reference value to compare our answers with, how do we measure whether or not our model is a good one? So on what basis can we evaluate? So what we need is a comparison where we know the answers. But the only situation where we know the answers is our training data. Our training data comes to us with labels. So for each input in our training data, we know the manually or however classified correct answer. So we are assuming those are the correct answers because otherwise our model building process will not make sense. So assuming that those are correct answers, we are building our model. So that's the only source of inputs and outputs where we know the\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"time. Everybody has. I mean, the school keeps a record of what happens in the model exams, what happens in the board exam. So it comes automatically. The bank will be keeping records of all the loans that it bought and what happened to the customers who bought loans. So this historical information is accumulated over time. On the other hand, in some situations, like the example I mentioned about classifying paintings, now, when you go into a museum or you go into some art gallery or something, the painting doesn't have a label on it, saying, this is a painting of this type and this is a painting of that type. So somebody, if you want to fit this training model to it, somebody has to sit and actually label these things for the algorithm. So there is a lot of work in it. So generating a lot of valid training data is itself a kind of computationally intensive task. How do you provide a lot of well trained examples? Because the assumption is that the labels that these training samples\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"a dog picture from a cat picture, or one which is neither of the two, it's not very easy to quantify that. And there the attributes in a picture are typically just if you think of a picture as a digital picture, it's a bunch of pixels and their colors and their arrangement, their relative arrangement. So even I'm saying, even if you have some domain knowledge, it's not very clear that the person's domain knowledge is aligned to the way the data is available. So what we are going to be doing is agnostic to the domain. So we are not going to believe anything or assume anything about the domain, except that we will want to validate at the end somehow that what we are doing is right. But in practice what you're saying makes sense that really to do supervised learning, it's much more realistic to do it in collaboration with somebody who understands a domain rather than just doing it blindly. Because also when you do it blindly, you might come up with solutions which make no sense. You\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"to show you some code before we come back to theory. So, is there any further questions? So, at the moment, I'm not expecting you to do anything with this code other than to understand that a, it is relatively painless to invoke a model in scikitlearn. And if you have this kind of visualization code, either you write it yourself or somebody gives it to you. You can then interpret your models visually and then experiment with it by changing things and seeing what happens. And that gives you a fair amount of insight both into your data and into how the model is working. So it gives you some indications about the limitations of that particular. Okay, so now I'm going to do something hopefully not unfamiliar to you. Right? At the beginning, when we talked about supervised learning, we said that we are trying to predict something, and those predictions can be in two types. So one type is what we have seen in the decision tree, which is a classification. So the predicted value is one from a\", metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"gain by the scattering of that attribute. So if we have high gain divided by high scattering, then the net normalized effect is lower. So you might choose an attribute which actually gives you a lower information gain overall, because the attribute itself is less static. And that's the thing that we want to achieve. Just to emphasize that when you have a machine learning algorithm, see generally, what is a machine learning algorithm doing? It's trying to describe the shape of the model based on the training data. So in this case it's literally the shape, because you have many possible trees you could construct, and the actual tree you construct depends on the data. And because you don't have any preconceptions about the data, you have to make sure that if there are these kind of patterns which disturb your algorithm, you will be able to counteract. So that's the purpose of this information gain ratio. It's not just the information gain alone, which is what we had initially. It's\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"its topic is education. And if it has game and team, then it is. So this is a special kind of association rule, where the right hand side of the rule is always a singleton, and it corresponds to a special type of item which is a category, in this case a topic. So when you have a table like this, the rows may have different number of entries. Or if you want to think about it as a table, then some columns may be blank. So not all columns are filled, but there's one last column which is filled. And now you want to now construct these rules corresponding to the first k minus one columns, implying the last column. And this now becomes something where these rules that you get out of this give you a kind of classifier. So this is a kind of a simplistic way of doing supervised learning. So that kind of brings me to the end of this basic treatment of classes, this market basket analysis. So what you're really looking for is correlations between sets of items across transactions, which we\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content=\"So remember, these x I's are actually not unknowns. These x I's known. So these x I's are what you get. The theta I's are the unknowns that you are trying to figure out. But in terms of the theta I's you can predict for a given xi. If you have computed some theta I's, then the answer is summation theta I x. So therefore the target that we have is clearly to find the best line. So let's assume we have a simple case of only one variable. So we have x one, x two, and so on. So we have n points. In reality, each of these x size is a vector of k, and the y, by convention, is always the label. So in the earlier thing, when we looked at that scikitlearn decision tree thing, we used capital x to denote the input matrix and y to denote the column matrix of output. So this is a normal standard convention in supervised learning that x's denote the inputs of the training data and y denotes the output label. In this case, it's not a label, but it's an output value. So in order to compute the best\", metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"base our model on should be somehow indicative of what we are going to predict. If we are going to take data pertaining to one group of individuals and extrapolate it to a completely different profile of individuals, then it's unlikely that this model that we built has any relevance. So there is this fundamental assumption. So we are not going to make this assumption mathematically precise in this course. So, in the advanced machine learning course, we will talk about a kind of theory of learning in which you can make this thing rigorous. But we are going to assume that there is a correlation between the distribution of training examples and the distribution of unseen data. So these are probabilistic, of course. Even if you have a similar set of data, you could draw samples which omit a few cases and have a few other cases. So it's always going to be a kind of probabilistic argument. But what you're saying is that this is a representative sample. So you're not saying that the examples\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"the data. So what we are trying to do is learn some kind of mathematical models from data. And this falls into two broad categories. So the first category is where you are given examples. So you are told, for instance, this is, for example, supposing you're trying to evaluate whether a painting is painted by a particular type of. So there are these pools of painting, like impressionists and cubists and so on. So you might be given a lot of pictures saying, this is cubist, this is not cubist, this is impressionist, and so on. And then from these examples which are given to you with manual information, you are supposed to build a model which will take an unknown painting and tell you from its features which of these categories. So this is a typical supervised learning kind of thing. Unsupervised learning is something which is closer to the data mining situation where you have data and you are looking for patterns, but you don't really have a clear idea beforehand what patterns they are.\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"particular distribution, I should keep a similar ratio. So this is called stratified sampling. But these are sort of different things. But the good thing for us is that in the libraries that we will use, this is an automatic step. You just have to say, split the data into train and test, and it'll do. So, training set and test set. That's it. So this is a little bit, what should I say? Confusing, because we actually call the whole thing also training, and then we split it. And then we again call this training and test. Right? So training data is a little bit of an ambiguous term. So training data is both the entire data set that you are given to start with. And then it is the specific choice that you make about how to split this data into a large part, which you will use for building the model, and a small part that you will reserve for validating the model. So depending on how much data you have, the usual practice is about 20% to 30% of it you keep aside. So you use about 70% to 80%\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"a fixed data set, and you are going to apply it to some other data set which you have not seen. So will that generalize well or not is the biggest question in machine learning. How do you know that the training data that you have used to build your model is actually representative of the data that you see in the real. And there could be many reasons why it is not valid. It could be because of sampling. So, for instance, you might be building a model for some consumer behavior by looking at one segment of. Maybe you are looking at the behavior of people who are in their, are building a model of how people behave, but your actual market consists of people who are maybe in their 40s, who have a very different way of dealing with things. So you need to be careful that the data that you're looking at is actually representative. So this is a huge problem and there's no correct answer. You can measure it, but you cannot. In some sense, if you could validate it, then this whole problem\", metadata={'source': 'audio_2.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_4=\" What is cross-validation?\""
      ],
      "metadata": {
        "id": "VVYvl3-cf_gg"
      },
      "id": "VVYvl3-cf_gg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = lotr.get_relevant_documents(query_4)\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_0g7VEogTz4",
        "outputId": "cb9b07c5-5b2b-4d1e-a20d-9ef97a6a6b31"
      },
      "id": "6_0g7VEogTz4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"But there may be more subtle things. Somebody might be talking about events, some kind of pop music events, and another person may be talking about some spiritual gatherings. And one person may be interested in pop music events, and another person may not be. And another person may be interested in spiritual gatherings, and the first person may not be. So then you can train these things. So in that sense, which words signal junk and which words don't signal junk is also a parameter of the model. Just like in this linear fit, the shape of the line is a parameter. So this is the learning part. So what we are going to do is look at different types of models, as I said, and then we will look at this parameter adjustment. How does the data actually determine the model, the concrete model? How do we build the best model that we can get for the given data? That's the algorithm. So we have a kind of model template. So we have a model template on this side, we have training data, and what we\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"a fixed data set, and you are going to apply it to some other data set which you have not seen. So will that generalize well or not is the biggest question in machine learning. How do you know that the training data that you have used to build your model is actually representative of the data that you see in the real. And there could be many reasons why it is not valid. It could be because of sampling. So, for instance, you might be building a model for some consumer behavior by looking at one segment of. Maybe you are looking at the behavior of people who are in their, are building a model of how people behave, but your actual market consists of people who are maybe in their 40s, who have a very different way of dealing with things. So you need to be careful that the data that you're looking at is actually representative. So this is a huge problem and there's no correct answer. You can measure it, but you cannot. In some sense, if you could validate it, then this whole problem\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content=\"what we are going to test it on are two different things. So we would like a model which does well with respect to the training data. So if you think about it as a situation where you want to minimize the errors, some kind of quantity, right? So you have a model which makes some predictions with respect to your training data, and you have the actual training data answers. So in a way, you would like to make these match as closely as possible. So it's a kind of optimization problem. You want to minimize the discrepancy between what your model does and what your training data tells you is the true value. So this is all possible for the training data because we know the answers. But when I move to a situation where I'm predicting the answers, the whole situation changes. Because if I could tell you what the right answers were, I wouldn't have to use this approach. So if I had an algorithmic way of telling you that this person should get a loan and that person should not get a loan, then\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"distribution changes slightly, one attribute might get better entropy than another attribute. And you will choose that question first. So the shape of the tree might vary a lot between these, so you may not get the same. Okay, so the question about cross validation, cross validation. What I'm saying is that you do not make a hard and fast choice once and for all to split your data this way. So you're taking your data and you're saying, hey, first let me leave out this 20% and build one model. So I am building multiple models. I'm building m one, m two, m three, m four, and m five. Each of these models is built using 80% of the test data, but a different 80%. So each of them leaves out some 20%. So I'm building five different models and comparing what I see in all these five. So the first thing is that if this approach is good, then in general, these five models should behave in a similar way with respect to the outcome. So if they all behave similarly, then I can decide what to do. So\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content='decision. One reason that this is important is remember that we talked about this cross validation. So what do we do in cross validation or even in normal validation? In normal validation or in cross validation. In either case, you pull out some random data, set data points from your input and build a tree on the rest. Now the question is, the model that you built from the rest, is it a stable structure in the sense that is it sensitive to how you chose your training and test data? And this example suggests that you are likely to get different models from different subsets of training data. So you then have to worry about what is your final model going to be. So if you test it on a particular test set, then maybe if you test it on a different test set, you might get an equivalent model, but it might have a very different structure, and maybe for other reasons, that structure might be more natural. So this is a generic problem with this kind of tree model, that it is very sensitive to', metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"a specification, but generating a concrete program from a generic program you can think of a model template as. So I just give you a line here which says a Y equal to Mx plus c. And here I want a specific m zero and C zero, which fits the given data in the best possible way, which is also part of the description of the algorithm. What does it mean for one line to be better than another line? So that's part of it. So the other side of this picture, as I mentioned, is when you don't have this training data, you don't have any examples that people have already labeled, but you are looking for some kind of patterns. So there is no guidance. So the thing about supervised learning is somebody should have gone through and given you this information before. Now, this information could have been collected over time. Maybe it's not manually collected, like the school marks. The school marks over time. Everybody has. I mean, the school keeps a record of what happens in the model exams, what\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"can measure it, but you cannot. In some sense, if you could validate it, then this whole problem becomes much simpler. But the whole difficulty with machine learning is exactly this, that there is no sensible way to predict the behavior or even when it will fail. Even if you could say that this is likely to work well here and not likely to work well there that itself would be a huge improvement, not even necessarily a very precise quantification, but just some indication. But all these are very speculative. So that's a huge challenge. So there are some theoretical things you can say which we may not, may or may not get to in this course. But it's a big problem. This is the so called generalization problem. So that's what basically, if you build association rules, is it going to hold or not? I don't know. Okay, sir, I had a question. We have been talking about items and transactions, but we haven't anywhere spoken about whether one customer, suppose if you're talking about somebody\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content=\"if given this input, will give you that corresponding output. So there is a correct output that you expect for every input, and then you can validate whether or not the program does it by feeding it different inputs of different types and seeing that it gives the expected output on a. But here the problem is that this expected output is not something that you know how to compute, and yet you need to make some statement, obviously, as to whether the model is good or bad, because if you can't validate that your model is doing well, you have no basis to use it. So this will be another issue that we will take up. How do we deal with this problem of evaluating performance when actually we don't have a yardstick measuring standard in some sense? So please stop me at any time. So if you think something, I'm going to get into a specific module very soon. So what we are going to look at are different. Start with very simple models. So what I'm going to do today is something called a decision\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"the best one. So more or less what you want to validate is, I have, say, seven different strategies to solve this problem using machine learning. And I want to check which one of them is good. So I need to compare. So once I compare, then I'm stuck with whatever I have. It may be that this gives me only 70% accuracy or some such metric, but the other models give me even less. So it's more really a comparative statement to start with, which is, is this method actually giving me something reasonable? And is it giving me better something than something else? So, for this one strategy is so called cross validation. So what you do is you take some fraction, say, in this case, it is one fifth. So 20%. So you take your data and you leave out. So you randomize it into five groups, which preserve, in some sense, the random behavior, so they partition it five ways. So if I leave out any one of these groups, it's as though I have taken the remaining 80% for training and this 20% for test. But\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"So we have this horizontal line and we have this one blue thing which is above the horizontal. So what if you remove the one or two of the bottom green things which come below the line, these are also wrong. Right? So the blue thing above the line was wrong in some sense. The green triangles below the line are also wrong. So instead of removing the widest blue, you can try to remove the narrowest green or the two narrowest greens or something and see what happens. So you just have to copy paste this code and just change the condition and all the visualization. You can just run it as it is and see, I have not done it, but I think you might get something different. So the predict outcome is not predictable. I cannot guarantee you that one or the other will produce a different output, but it can happen. And this is generally something which one has to be mindful of when you're dealing with decision. One reason that this is important is remember that we talked about this cross validation.\", metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"these values in that example. So unless you specify that, you cannot say that this is unlikely to be true or this is likely to be true, because it will be specific to the interpretation. But the problem now, we have now reduced it to one which is uninterpreted. We are just talking about abstract items. So there was a question in the chat about dimensionality reduction connected to PCA. So, yes, the PCA will be one part of it, but there are also other things that we will see. Sir, I have a question. Yeah. When we model this problem in this way, we didn't capture the frequency of items in a transaction. We were just looking at whether or not that item is present or not. Yeah, but I think for most of these examples, whether someone's buying from a shop or whether it's words in a document, that frequency will be a part of it. Right. Which we are not capturing here. Yeah. So usually this is how mathematical models work. You start with the most basic model, and then you add any features\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"its topic is education. And if it has game and team, then it is. So this is a special kind of association rule, where the right hand side of the rule is always a singleton, and it corresponds to a special type of item which is a category, in this case a topic. So when you have a table like this, the rows may have different number of entries. Or if you want to think about it as a table, then some columns may be blank. So not all columns are filled, but there's one last column which is filled. And now you want to now construct these rules corresponding to the first k minus one columns, implying the last column. And this now becomes something where these rules that you get out of this give you a kind of classifier. So this is a kind of a simplistic way of doing supervised learning. So that kind of brings me to the end of this basic treatment of classes, this market basket analysis. So what you're really looking for is correlations between sets of items across transactions, which we\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content=\"what you're saying is that this is a representative sample. So you're not saying that the examples have every possible situation that you are likely to use for judgment, but you're really talking at the level of probabilities. You're saying that the probability distribution of the training is somehow identical to that of the unseen data on which you are going to make the prediction. So this is going to be your training and this is going to be your prediction. So this is a fundamental assumption. If this assumption does not hold, then whatever you try to do doesn't really have any basis. So this is something that we have to assume, and we will talk about later on what this assumption means. Maybe not in this course, but in later courses. But for now, let us assume this. So the next question is, what does it mean to learn? Right? So, as we saw in this loan data set, 60% of the loans were granted, so nine by 15. So if I were to just say yes, supposing I don't have an interesting model\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content='we had, which is, how do we query the effectiveness of our model? So how do we validate whether the model we have built is right or not? So what I had mentioned earlier is that there is a fundamental difference between normal, say test software validation and this machine learning model validation, because when we have some software, we write some code in a traditional setting, we have an expectation, we know something about how the inputs should be mapped to the outputs. So we can create this kind of a test suite which maybe checks the boundary conditions, as they are called. Some extreme cases where you want to make sure that the software is doing the right thing, and then we compare the output with what we know should be the output. Right? So we take the program output and compare it with the expected answer. So we have a notion of a correct answer to compare. So the problem with the classification model is that this correct answer is not known. I mean, if we knew the answer, if we', metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"So remember, these x I's are actually not unknowns. These x I's known. So these x I's are what you get. The theta I's are the unknowns that you are trying to figure out. But in terms of the theta I's you can predict for a given xi. If you have computed some theta I's, then the answer is summation theta I x. So therefore the target that we have is clearly to find the best line. So let's assume we have a simple case of only one variable. So we have x one, x two, and so on. So we have n points. In reality, each of these x size is a vector of k, and the y, by convention, is always the label. So in the earlier thing, when we looked at that scikitlearn decision tree thing, we used capital x to denote the input matrix and y to denote the column matrix of output. So this is a normal standard convention in supervised learning that x's denote the inputs of the training data and y denotes the output label. In this case, it's not a label, but it's an output value. So in order to compute the best\", metadata={'source': 'audio_5.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reordered_docs = reordering.transform_documents(docs)\n",
        "\n",
        "# Confirm that the 4 relevant documents are at beginning and end.\n",
        "reordered_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Mi9A5YLgrxI",
        "outputId": "fad14fef-5e98-4aae-cf36-3a4ed06c347e"
      },
      "id": "7Mi9A5YLgrxI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"But there may be more subtle things. Somebody might be talking about events, some kind of pop music events, and another person may be talking about some spiritual gatherings. And one person may be interested in pop music events, and another person may not be. And another person may be interested in spiritual gatherings, and the first person may not be. So then you can train these things. So in that sense, which words signal junk and which words don't signal junk is also a parameter of the model. Just like in this linear fit, the shape of the line is a parameter. So this is the learning part. So what we are going to do is look at different types of models, as I said, and then we will look at this parameter adjustment. How does the data actually determine the model, the concrete model? How do we build the best model that we can get for the given data? That's the algorithm. So we have a kind of model template. So we have a model template on this side, we have training data, and what we\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"what we are going to test it on are two different things. So we would like a model which does well with respect to the training data. So if you think about it as a situation where you want to minimize the errors, some kind of quantity, right? So you have a model which makes some predictions with respect to your training data, and you have the actual training data answers. So in a way, you would like to make these match as closely as possible. So it's a kind of optimization problem. You want to minimize the discrepancy between what your model does and what your training data tells you is the true value. So this is all possible for the training data because we know the answers. But when I move to a situation where I'm predicting the answers, the whole situation changes. Because if I could tell you what the right answers were, I wouldn't have to use this approach. So if I had an algorithmic way of telling you that this person should get a loan and that person should not get a loan, then\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content='decision. One reason that this is important is remember that we talked about this cross validation. So what do we do in cross validation or even in normal validation? In normal validation or in cross validation. In either case, you pull out some random data, set data points from your input and build a tree on the rest. Now the question is, the model that you built from the rest, is it a stable structure in the sense that is it sensitive to how you chose your training and test data? And this example suggests that you are likely to get different models from different subsets of training data. So you then have to worry about what is your final model going to be. So if you test it on a particular test set, then maybe if you test it on a different test set, you might get an equivalent model, but it might have a very different structure, and maybe for other reasons, that structure might be more natural. So this is a generic problem with this kind of tree model, that it is very sensitive to', metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"can measure it, but you cannot. In some sense, if you could validate it, then this whole problem becomes much simpler. But the whole difficulty with machine learning is exactly this, that there is no sensible way to predict the behavior or even when it will fail. Even if you could say that this is likely to work well here and not likely to work well there that itself would be a huge improvement, not even necessarily a very precise quantification, but just some indication. But all these are very speculative. So that's a huge challenge. So there are some theoretical things you can say which we may not, may or may not get to in this course. But it's a big problem. This is the so called generalization problem. So that's what basically, if you build association rules, is it going to hold or not? I don't know. Okay, sir, I had a question. We have been talking about items and transactions, but we haven't anywhere spoken about whether one customer, suppose if you're talking about somebody\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content=\"the best one. So more or less what you want to validate is, I have, say, seven different strategies to solve this problem using machine learning. And I want to check which one of them is good. So I need to compare. So once I compare, then I'm stuck with whatever I have. It may be that this gives me only 70% accuracy or some such metric, but the other models give me even less. So it's more really a comparative statement to start with, which is, is this method actually giving me something reasonable? And is it giving me better something than something else? So, for this one strategy is so called cross validation. So what you do is you take some fraction, say, in this case, it is one fifth. So 20%. So you take your data and you leave out. So you randomize it into five groups, which preserve, in some sense, the random behavior, so they partition it five ways. So if I leave out any one of these groups, it's as though I have taken the remaining 80% for training and this 20% for test. But\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"these values in that example. So unless you specify that, you cannot say that this is unlikely to be true or this is likely to be true, because it will be specific to the interpretation. But the problem now, we have now reduced it to one which is uninterpreted. We are just talking about abstract items. So there was a question in the chat about dimensionality reduction connected to PCA. So, yes, the PCA will be one part of it, but there are also other things that we will see. Sir, I have a question. Yeah. When we model this problem in this way, we didn't capture the frequency of items in a transaction. We were just looking at whether or not that item is present or not. Yeah, but I think for most of these examples, whether someone's buying from a shop or whether it's words in a document, that frequency will be a part of it. Right. Which we are not capturing here. Yeah. So usually this is how mathematical models work. You start with the most basic model, and then you add any features\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"what you're saying is that this is a representative sample. So you're not saying that the examples have every possible situation that you are likely to use for judgment, but you're really talking at the level of probabilities. You're saying that the probability distribution of the training is somehow identical to that of the unseen data on which you are going to make the prediction. So this is going to be your training and this is going to be your prediction. So this is a fundamental assumption. If this assumption does not hold, then whatever you try to do doesn't really have any basis. So this is something that we have to assume, and we will talk about later on what this assumption means. Maybe not in this course, but in later courses. But for now, let us assume this. So the next question is, what does it mean to learn? Right? So, as we saw in this loan data set, 60% of the loans were granted, so nine by 15. So if I were to just say yes, supposing I don't have an interesting model\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"So remember, these x I's are actually not unknowns. These x I's known. So these x I's are what you get. The theta I's are the unknowns that you are trying to figure out. But in terms of the theta I's you can predict for a given xi. If you have computed some theta I's, then the answer is summation theta I x. So therefore the target that we have is clearly to find the best line. So let's assume we have a simple case of only one variable. So we have x one, x two, and so on. So we have n points. In reality, each of these x size is a vector of k, and the y, by convention, is always the label. So in the earlier thing, when we looked at that scikitlearn decision tree thing, we used capital x to denote the input matrix and y to denote the column matrix of output. So this is a normal standard convention in supervised learning that x's denote the inputs of the training data and y denotes the output label. In this case, it's not a label, but it's an output value. So in order to compute the best\", metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content='we had, which is, how do we query the effectiveness of our model? So how do we validate whether the model we have built is right or not? So what I had mentioned earlier is that there is a fundamental difference between normal, say test software validation and this machine learning model validation, because when we have some software, we write some code in a traditional setting, we have an expectation, we know something about how the inputs should be mapped to the outputs. So we can create this kind of a test suite which maybe checks the boundary conditions, as they are called. Some extreme cases where you want to make sure that the software is doing the right thing, and then we compare the output with what we know should be the output. Right? So we take the program output and compare it with the expected answer. So we have a notion of a correct answer to compare. So the problem with the classification model is that this correct answer is not known. I mean, if we knew the answer, if we', metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"its topic is education. And if it has game and team, then it is. So this is a special kind of association rule, where the right hand side of the rule is always a singleton, and it corresponds to a special type of item which is a category, in this case a topic. So when you have a table like this, the rows may have different number of entries. Or if you want to think about it as a table, then some columns may be blank. So not all columns are filled, but there's one last column which is filled. And now you want to now construct these rules corresponding to the first k minus one columns, implying the last column. And this now becomes something where these rules that you get out of this give you a kind of classifier. So this is a kind of a simplistic way of doing supervised learning. So that kind of brings me to the end of this basic treatment of classes, this market basket analysis. So what you're really looking for is correlations between sets of items across transactions, which we\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content=\"So we have this horizontal line and we have this one blue thing which is above the horizontal. So what if you remove the one or two of the bottom green things which come below the line, these are also wrong. Right? So the blue thing above the line was wrong in some sense. The green triangles below the line are also wrong. So instead of removing the widest blue, you can try to remove the narrowest green or the two narrowest greens or something and see what happens. So you just have to copy paste this code and just change the condition and all the visualization. You can just run it as it is and see, I have not done it, but I think you might get something different. So the predict outcome is not predictable. I cannot guarantee you that one or the other will produce a different output, but it can happen. And this is generally something which one has to be mindful of when you're dealing with decision. One reason that this is important is remember that we talked about this cross validation.\", metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"if given this input, will give you that corresponding output. So there is a correct output that you expect for every input, and then you can validate whether or not the program does it by feeding it different inputs of different types and seeing that it gives the expected output on a. But here the problem is that this expected output is not something that you know how to compute, and yet you need to make some statement, obviously, as to whether the model is good or bad, because if you can't validate that your model is doing well, you have no basis to use it. So this will be another issue that we will take up. How do we deal with this problem of evaluating performance when actually we don't have a yardstick measuring standard in some sense? So please stop me at any time. So if you think something, I'm going to get into a specific module very soon. So what we are going to look at are different. Start with very simple models. So what I'm going to do today is something called a decision\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"a specification, but generating a concrete program from a generic program you can think of a model template as. So I just give you a line here which says a Y equal to Mx plus c. And here I want a specific m zero and C zero, which fits the given data in the best possible way, which is also part of the description of the algorithm. What does it mean for one line to be better than another line? So that's part of it. So the other side of this picture, as I mentioned, is when you don't have this training data, you don't have any examples that people have already labeled, but you are looking for some kind of patterns. So there is no guidance. So the thing about supervised learning is somebody should have gone through and given you this information before. Now, this information could have been collected over time. Maybe it's not manually collected, like the school marks. The school marks over time. Everybody has. I mean, the school keeps a record of what happens in the model exams, what\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"distribution changes slightly, one attribute might get better entropy than another attribute. And you will choose that question first. So the shape of the tree might vary a lot between these, so you may not get the same. Okay, so the question about cross validation, cross validation. What I'm saying is that you do not make a hard and fast choice once and for all to split your data this way. So you're taking your data and you're saying, hey, first let me leave out this 20% and build one model. So I am building multiple models. I'm building m one, m two, m three, m four, and m five. Each of these models is built using 80% of the test data, but a different 80%. So each of them leaves out some 20%. So I'm building five different models and comparing what I see in all these five. So the first thing is that if this approach is good, then in general, these five models should behave in a similar way with respect to the outcome. So if they all behave similarly, then I can decide what to do. So\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"a fixed data set, and you are going to apply it to some other data set which you have not seen. So will that generalize well or not is the biggest question in machine learning. How do you know that the training data that you have used to build your model is actually representative of the data that you see in the real. And there could be many reasons why it is not valid. It could be because of sampling. So, for instance, you might be building a model for some consumer behavior by looking at one segment of. Maybe you are looking at the behavior of people who are in their, are building a model of how people behave, but your actual market consists of people who are maybe in their 40s, who have a very different way of dealing with things. So you need to be careful that the data that you're looking at is actually representative. So this is a huge problem and there's no correct answer. You can measure it, but you cannot. In some sense, if you could validate it, then this whole problem\", metadata={'source': 'audio_2.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query_5=\"What is the process of building the decision tree classifier, and how is it trained on the dataset?\""
      ],
      "metadata": {
        "id": "zK57Px_bhELw"
      },
      "id": "zK57Px_bhELw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = lotr.get_relevant_documents(query_5)\n",
        "docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPb4bN-MhbL4",
        "outputId": "a974df8c-712b-4036-a466-5c12bdb195de"
      },
      "id": "RPb4bN-MhbL4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"the order, sometimes we don't. Addresses, of course, are written in a million different ways. So there are all kinds of issues with just getting the data to a format where you can work on it. So this is an entirely different ballgame. It's much more kind of. There are lots of tools and techniques to deal with this, but that's not really going to be the focus of the course. So, in a sense, if you want to think about it, this data mining aspect will be almost missing from this course, even though it's part of the title. So what we are really going to look at is the machine learning aspect. So learning means you are trying to understand something that you don't know before. And machine learning suggests that it's done automatically. It's done by now machine as a computer. So there is an algorithm which learns something about, again, it's always with respect to data. So it's something about the data. So what we are trying to do is learn some kind of mathematical models from data. And this\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"its topic is education. And if it has game and team, then it is. So this is a special kind of association rule, where the right hand side of the rule is always a singleton, and it corresponds to a special type of item which is a category, in this case a topic. So when you have a table like this, the rows may have different number of entries. Or if you want to think about it as a table, then some columns may be blank. So not all columns are filled, but there's one last column which is filled. And now you want to now construct these rules corresponding to the first k minus one columns, implying the last column. And this now becomes something where these rules that you get out of this give you a kind of classifier. So this is a kind of a simplistic way of doing supervised learning. So that kind of brings me to the end of this basic treatment of classes, this market basket analysis. So what you're really looking for is correlations between sets of items across transactions, which we\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content=\"too, in order to. Sorry, I didn't hear you. Can you say louder? We need to take all the possible tree. That could happen. Is it not necessarily all the possible trees? So that is some issue that we have to deal with. So what we are going to try and build, we are not going to build all the possible trees because that would be too many trees. So we want to build a good tree as far as possible. And then we have to ask, what is a good tree? And with respect to that good tree, what we are saying is there is a kind of ranking of attributes. So even in this order, the tree will tell us a little bit about which attribute is more important. So there is a kind of implicit ranking which is happening, and an attribute which does not appear at all in our tree that we construct. If it turns out that otherwise it's a good tree, then we could argue that that attribute has no significance. But even otherwise, one of the things, byproducts of decision tree will be a kind of implicit importance, ranking\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"So last time we started with supervised learning in earnest, and we were looking at this decision tree model. So, in a decision tree model, you have essentially a table in which the columns are the. So each item, a row in the table and one special column denotes the class that you are trying to classify. And we assumed it's a binary classification. So the class is zero, one, or yes, no, or whatever you want to interpret. The two categories are. So the algorithm was very simple. At a high level, what you want to do is choose an attribute based on the answer to the question that you're asking about that attribute. The data splits, and then you take each partition, ask another question. So that's the thing. And you want to come down and keep asking questions until either you have reached, like these situations here, a partition in which all the values of the class variable are the same. So you have a uniform class level or you have run out of questions, because we can only ask in any path\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"about what's going on behind the algorithm in order to make best use of it when it is not producing an answer which is acceptable to you. But as far as using it per se, all you need to do is set up the appropriate. So here it's a decision tree, but pretty much the same. So these two steps that you see here, these two steps. So this is a pretty canonical style of programming. In this scikitler, you import the right type of classifier, you build a classifier of that type with the parameters that you think are reasonable for your application, and then you pass it the training data and say fit. Now here, one thing we have not done, for instance, is to segregate out, we talked about training and test data. We have not done that. So that's also something that you can do. Before you set it up, you might get all the iris data and then you might want to keep part of it aside. So we will see as we go along how to do all these things. But for the moment, it's taking all the iris data which has\", metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"the data. So what we are trying to do is learn some kind of mathematical models from data. And this falls into two broad categories. So the first category is where you are given examples. So you are told, for instance, this is, for example, supposing you're trying to evaluate whether a painting is painted by a particular type of. So there are these pools of painting, like impressionists and cubists and so on. So you might be given a lot of pictures saying, this is cubist, this is not cubist, this is impressionist, and so on. And then from these examples which are given to you with manual information, you are supposed to build a model which will take an unknown painting and tell you from its features which of these categories. So this is a typical supervised learning kind of thing. Unsupervised learning is something which is closer to the data mining situation where you have data and you are looking for patterns, but you don't really have a clear idea beforehand what patterns they are.\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"a slightly different presentation of the idea. Okay, so now, as I said, this whole thing so far has been largely a kind of algorithmic problem, right? In some sense, if I fix the set of items and the set of transactions and the set of the two thresholds, the support and the confidence threshold, then for any x, comma y, either it is true or it is not true. So there is a fixed answer. So the answer is known. So this is something where I can actually validate that you have either enumerated all the association rules or you have missed out something. So technically there is no learning involved. It's more an algorithmic question. So how does one connect this to learning? Well, in specific context, you can interpret these rules as classification rules. So, remember we said supervised learning says, if this is there, then it is a fraud. If this thing is not there, then it is not a fraud, and so on. So, let's look at a typical example. So, supposing we have some question which is about\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content=\"happen. So in such a situation, also you have to stop and say something. So your decision tree, finally, what is the goal of decision tree is going to say? If this is the combination of attributes that I see in an item, is my answer yes? Or if I am this case, the answer is clear. Whatever label I have reached uniformly in that group, that is the answer. So if I have, as we said, if the person is young and has a job, I will say yes, I don't have to say anything else. If the person is middle aged and does not own a house, I will just say no. But if there is a mixed thing, then how do I choose? So there is no good way to choose. So all we can say is that at that point, hopefully there is some uneven distribution. So maybe there are a few unusual cases who had all the correct attributes as far as what is written down, but due to some mess up and some hidden kind of features, they didn't get it. So you could basically just take the majority, right? So supposing you do all this and you come\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"these groups, it's as though I have taken the remaining 80% for training and this 20% for test. But because I don't want to actually think of it this way, I will actually keep doing this for each one. So I will leave out the first 20%, then I will leave out the second 20%. So I will do this. If I have like k chunks, I will do this k times in each chunk. Each model I will build using all but one of these chunks. So this then will solve this problem of many problems. It will solve the problem where you don't have enough data to begin with to afford to not look at some of it, because the interesting things may be in that sum of it. Now, what will you do with this whole thing? Well, you have five. Typically, each of these models are going to be different because we saw with the decision tree, it's kind of the questions that you ask depend on the distribution of the different roles. And if the distribution changes slightly, one attribute might get better entropy than another attribute. And\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"and is therefore picking up some peculiarities which don't necessarily exist within. So one of the things we mentioned in passing was that we like short trees for two reasons. One is because they are easier to explain. The second thing, which I claim without any justification, is that they generalize better. So here, priority, they are saying, let us not construct deep trees. So whatever tree we construct, we are going to stop it when it reaches. So it's a two step process, right? So what you do is you first say what are the parameters for the decision tree classifier? So he says, I want a decision tree classifier to be set up with this random state 42 and which will not grow to more than depth two. And then I have to actually construct the classifier for a particular data set. So that's the next thing. So I use this fit function, right? In some sense this creates a decision tree object with certain operating parameters, and then you pass it the training data in the form of the input\", metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"model, or a numerical prediction model. As we said, in case you're trying to predict a number or category, the category is more like a classification problem, right? I give you something and I want you to classify it as yes, no, good, bad, or we have unsupervised learning where we are looking for some kind of structure, and usually this is in the form of clustering, but we also have to deal with these outliers, as I said. And then sometimes you want to simplify the problem by knocking off certain dimensions or unrolling the object or so. So if you look at the popular press and the popular literature, all the focus of machine learning is actually on the first one. So supervised learning is by far the more attractive and the more, should I say, attractive, I guess it's the more attractive aspect of machine learning. This is what people are really looking for. But unfortunately, as I said, to do effective supervised learning, you need to actually get a lot of training data. And this is\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"can measure it, but you cannot. In some sense, if you could validate it, then this whole problem becomes much simpler. But the whole difficulty with machine learning is exactly this, that there is no sensible way to predict the behavior or even when it will fail. Even if you could say that this is likely to work well here and not likely to work well there that itself would be a huge improvement, not even necessarily a very precise quantification, but just some indication. But all these are very speculative. So that's a huge challenge. So there are some theoretical things you can say which we may not, may or may not get to in this course. But it's a big problem. This is the so called generalization problem. So that's what basically, if you build association rules, is it going to hold or not? I don't know. Okay, sir, I had a question. We have been talking about items and transactions, but we haven't anywhere spoken about whether one customer, suppose if you're talking about somebody\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content=\"use either this entropy idea or this genie index, and it gives me a sharper curve, and this sharper practice turns out to be better. So that's how you build a decision tree. You build a decision tree by applying one of these two nonlinear things. If you come up to the third thing, it's also fine. It's just that these two happen to be standard things. They are both borrowed from other areas where they have a long and established history. So, as I said, genie index comes from economics and entropy comes from information. So we'll stop here. So, any questions? It okay, if there are no questions, then we'll continue with this discussion of decision trees on Thursday when we meet next.\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"we are building our model. So that's the only source of inputs and outputs where we know the answer. So the only solution really is to use that. So we have to take that training data and keep some of it aside because we are optimizing our model, as we saw in the decision tree, we are optimizing it to give correct answers on the training data. So therefore it doesn't make sense to evaluate it back on the same inputs which are used to construct the tree. But if I withhold some data, so I basically take my training data as a whole and then I kind of split this and say, do not use this part, only use this part to build my model. Then the model that I built from here, I can ask, how does it do on that? And there is no problem with this because the model has not seen that data. So it's not been biased by the data on the right hand side. So this data has never been used in the model building process. So it is as good as unknown data as far as the model, but it is unknown to the model. But\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"and two, three are the petal. So it's taking all the rows and it's taking the third and fourth columns. So we're throwing away two columns. So we are making it, instead of a four column array, we are making it into a two column array. And in this data. So when you load the data set, it automatically produces these two subparts, iris data and iris target. So target is the classification variable. Remember, in this case, the classification variable is a three way thing, right? There are three types of irises that we saw, so it will be essentially a number, zero, one. And now to get this decision tree classifier, we have to take this function that we have imported. So we say take a decision tree classifier. We have to provide it with, again some random state because it uses some randomization inside it. And now this is something which we have not talked about. So we discussed that we will build a decision tree normally until we either achieve some pure leaf nodes where the classification\", metadata={'source': 'audio_5.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reordered_docs = reordering.transform_documents(docs)\n",
        "\n",
        "# Confirm that the 4 relevant documents are at beginning and end.\n",
        "reordered_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT1xXXXRhpqf",
        "outputId": "380c7cfb-275a-4f2c-98a5-6e58cf6a750c"
      },
      "id": "QT1xXXXRhpqf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"the order, sometimes we don't. Addresses, of course, are written in a million different ways. So there are all kinds of issues with just getting the data to a format where you can work on it. So this is an entirely different ballgame. It's much more kind of. There are lots of tools and techniques to deal with this, but that's not really going to be the focus of the course. So, in a sense, if you want to think about it, this data mining aspect will be almost missing from this course, even though it's part of the title. So what we are really going to look at is the machine learning aspect. So learning means you are trying to understand something that you don't know before. And machine learning suggests that it's done automatically. It's done by now machine as a computer. So there is an algorithm which learns something about, again, it's always with respect to data. So it's something about the data. So what we are trying to do is learn some kind of mathematical models from data. And this\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"too, in order to. Sorry, I didn't hear you. Can you say louder? We need to take all the possible tree. That could happen. Is it not necessarily all the possible trees? So that is some issue that we have to deal with. So what we are going to try and build, we are not going to build all the possible trees because that would be too many trees. So we want to build a good tree as far as possible. And then we have to ask, what is a good tree? And with respect to that good tree, what we are saying is there is a kind of ranking of attributes. So even in this order, the tree will tell us a little bit about which attribute is more important. So there is a kind of implicit ranking which is happening, and an attribute which does not appear at all in our tree that we construct. If it turns out that otherwise it's a good tree, then we could argue that that attribute has no significance. But even otherwise, one of the things, byproducts of decision tree will be a kind of implicit importance, ranking\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"about what's going on behind the algorithm in order to make best use of it when it is not producing an answer which is acceptable to you. But as far as using it per se, all you need to do is set up the appropriate. So here it's a decision tree, but pretty much the same. So these two steps that you see here, these two steps. So this is a pretty canonical style of programming. In this scikitler, you import the right type of classifier, you build a classifier of that type with the parameters that you think are reasonable for your application, and then you pass it the training data and say fit. Now here, one thing we have not done, for instance, is to segregate out, we talked about training and test data. We have not done that. So that's also something that you can do. Before you set it up, you might get all the iris data and then you might want to keep part of it aside. So we will see as we go along how to do all these things. But for the moment, it's taking all the iris data which has\", metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"a slightly different presentation of the idea. Okay, so now, as I said, this whole thing so far has been largely a kind of algorithmic problem, right? In some sense, if I fix the set of items and the set of transactions and the set of the two thresholds, the support and the confidence threshold, then for any x, comma y, either it is true or it is not true. So there is a fixed answer. So the answer is known. So this is something where I can actually validate that you have either enumerated all the association rules or you have missed out something. So technically there is no learning involved. It's more an algorithmic question. So how does one connect this to learning? Well, in specific context, you can interpret these rules as classification rules. So, remember we said supervised learning says, if this is there, then it is a fraud. If this thing is not there, then it is not a fraud, and so on. So, let's look at a typical example. So, supposing we have some question which is about\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content=\"these groups, it's as though I have taken the remaining 80% for training and this 20% for test. But because I don't want to actually think of it this way, I will actually keep doing this for each one. So I will leave out the first 20%, then I will leave out the second 20%. So I will do this. If I have like k chunks, I will do this k times in each chunk. Each model I will build using all but one of these chunks. So this then will solve this problem of many problems. It will solve the problem where you don't have enough data to begin with to afford to not look at some of it, because the interesting things may be in that sum of it. Now, what will you do with this whole thing? Well, you have five. Typically, each of these models are going to be different because we saw with the decision tree, it's kind of the questions that you ask depend on the distribution of the different roles. And if the distribution changes slightly, one attribute might get better entropy than another attribute. And\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"model, or a numerical prediction model. As we said, in case you're trying to predict a number or category, the category is more like a classification problem, right? I give you something and I want you to classify it as yes, no, good, bad, or we have unsupervised learning where we are looking for some kind of structure, and usually this is in the form of clustering, but we also have to deal with these outliers, as I said. And then sometimes you want to simplify the problem by knocking off certain dimensions or unrolling the object or so. So if you look at the popular press and the popular literature, all the focus of machine learning is actually on the first one. So supervised learning is by far the more attractive and the more, should I say, attractive, I guess it's the more attractive aspect of machine learning. This is what people are really looking for. But unfortunately, as I said, to do effective supervised learning, you need to actually get a lot of training data. And this is\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"use either this entropy idea or this genie index, and it gives me a sharper curve, and this sharper practice turns out to be better. So that's how you build a decision tree. You build a decision tree by applying one of these two nonlinear things. If you come up to the third thing, it's also fine. It's just that these two happen to be standard things. They are both borrowed from other areas where they have a long and established history. So, as I said, genie index comes from economics and entropy comes from information. So we'll stop here. So, any questions? It okay, if there are no questions, then we'll continue with this discussion of decision trees on Thursday when we meet next.\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"and two, three are the petal. So it's taking all the rows and it's taking the third and fourth columns. So we're throwing away two columns. So we are making it, instead of a four column array, we are making it into a two column array. And in this data. So when you load the data set, it automatically produces these two subparts, iris data and iris target. So target is the classification variable. Remember, in this case, the classification variable is a three way thing, right? There are three types of irises that we saw, so it will be essentially a number, zero, one. And now to get this decision tree classifier, we have to take this function that we have imported. So we say take a decision tree classifier. We have to provide it with, again some random state because it uses some randomization inside it. And now this is something which we have not talked about. So we discussed that we will build a decision tree normally until we either achieve some pure leaf nodes where the classification\", metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"we are building our model. So that's the only source of inputs and outputs where we know the answer. So the only solution really is to use that. So we have to take that training data and keep some of it aside because we are optimizing our model, as we saw in the decision tree, we are optimizing it to give correct answers on the training data. So therefore it doesn't make sense to evaluate it back on the same inputs which are used to construct the tree. But if I withhold some data, so I basically take my training data as a whole and then I kind of split this and say, do not use this part, only use this part to build my model. Then the model that I built from here, I can ask, how does it do on that? And there is no problem with this because the model has not seen that data. So it's not been biased by the data on the right hand side. So this data has never been used in the model building process. So it is as good as unknown data as far as the model, but it is unknown to the model. But\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"can measure it, but you cannot. In some sense, if you could validate it, then this whole problem becomes much simpler. But the whole difficulty with machine learning is exactly this, that there is no sensible way to predict the behavior or even when it will fail. Even if you could say that this is likely to work well here and not likely to work well there that itself would be a huge improvement, not even necessarily a very precise quantification, but just some indication. But all these are very speculative. So that's a huge challenge. So there are some theoretical things you can say which we may not, may or may not get to in this course. But it's a big problem. This is the so called generalization problem. So that's what basically, if you build association rules, is it going to hold or not? I don't know. Okay, sir, I had a question. We have been talking about items and transactions, but we haven't anywhere spoken about whether one customer, suppose if you're talking about somebody\", metadata={'source': 'audio_2.txt'}),\n",
              " Document(page_content=\"and is therefore picking up some peculiarities which don't necessarily exist within. So one of the things we mentioned in passing was that we like short trees for two reasons. One is because they are easier to explain. The second thing, which I claim without any justification, is that they generalize better. So here, priority, they are saying, let us not construct deep trees. So whatever tree we construct, we are going to stop it when it reaches. So it's a two step process, right? So what you do is you first say what are the parameters for the decision tree classifier? So he says, I want a decision tree classifier to be set up with this random state 42 and which will not grow to more than depth two. And then I have to actually construct the classifier for a particular data set. So that's the next thing. So I use this fit function, right? In some sense this creates a decision tree object with certain operating parameters, and then you pass it the training data in the form of the input\", metadata={'source': 'audio_5.txt'}),\n",
              " Document(page_content=\"happen. So in such a situation, also you have to stop and say something. So your decision tree, finally, what is the goal of decision tree is going to say? If this is the combination of attributes that I see in an item, is my answer yes? Or if I am this case, the answer is clear. Whatever label I have reached uniformly in that group, that is the answer. So if I have, as we said, if the person is young and has a job, I will say yes, I don't have to say anything else. If the person is middle aged and does not own a house, I will just say no. But if there is a mixed thing, then how do I choose? So there is no good way to choose. So all we can say is that at that point, hopefully there is some uneven distribution. So maybe there are a few unusual cases who had all the correct attributes as far as what is written down, but due to some mess up and some hidden kind of features, they didn't get it. So you could basically just take the majority, right? So supposing you do all this and you come\", metadata={'source': 'audio_3.txt'}),\n",
              " Document(page_content=\"the data. So what we are trying to do is learn some kind of mathematical models from data. And this falls into two broad categories. So the first category is where you are given examples. So you are told, for instance, this is, for example, supposing you're trying to evaluate whether a painting is painted by a particular type of. So there are these pools of painting, like impressionists and cubists and so on. So you might be given a lot of pictures saying, this is cubist, this is not cubist, this is impressionist, and so on. And then from these examples which are given to you with manual information, you are supposed to build a model which will take an unknown painting and tell you from its features which of these categories. So this is a typical supervised learning kind of thing. Unsupervised learning is something which is closer to the data mining situation where you have data and you are looking for patterns, but you don't really have a clear idea beforehand what patterns they are.\", metadata={'source': 'audio_1.txt'}),\n",
              " Document(page_content=\"So last time we started with supervised learning in earnest, and we were looking at this decision tree model. So, in a decision tree model, you have essentially a table in which the columns are the. So each item, a row in the table and one special column denotes the class that you are trying to classify. And we assumed it's a binary classification. So the class is zero, one, or yes, no, or whatever you want to interpret. The two categories are. So the algorithm was very simple. At a high level, what you want to do is choose an attribute based on the answer to the question that you're asking about that attribute. The data splits, and then you take each partition, ask another question. So that's the thing. And you want to come down and keep asking questions until either you have reached, like these situations here, a partition in which all the values of the class variable are the same. So you have a uniform class level or you have run out of questions, because we can only ask in any path\", metadata={'source': 'audio_4.txt'}),\n",
              " Document(page_content=\"its topic is education. And if it has game and team, then it is. So this is a special kind of association rule, where the right hand side of the rule is always a singleton, and it corresponds to a special type of item which is a category, in this case a topic. So when you have a table like this, the rows may have different number of entries. Or if you want to think about it as a table, then some columns may be blank. So not all columns are filled, but there's one last column which is filled. And now you want to now construct these rules corresponding to the first k minus one columns, implying the last column. And this now becomes something where these rules that you get out of this give you a kind of classifier. So this is a kind of a simplistic way of doing supervised learning. So that kind of brings me to the end of this basic treatment of classes, this market basket analysis. So what you're really looking for is correlations between sets of items across transactions, which we\", metadata={'source': 'audio_2.txt'})]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for chunks in lotr.get_relevant_documents(\"What is supervised Learning\"):\n",
        "    print(chunks.page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHTARGQt7sjS",
        "outputId": "ff39498c-c636-42c0-ccad-05db12539fe9"
      },
      "id": "XHTARGQt7sjS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "are looking for patterns, but you don't really have a clear idea beforehand what patterns they are. So a typical example of this might be that a company which is selling something might want to know some information about the demographics of its customers. So what are the groupings? I mean, which age groups? What is the proportion of people who are, say, between 20 and 30 who buy their products, people above 50 who buy their products, and so on. So this kind of thing is unsupervised because you don't know what you're going to get. But after you get this information, maybe you can put it to good use. So these are broadly the two types of things that are there. There is a third type of machine learning called reinforcement learning, which we are not going to talk about at all in this course. So to look at supervised learning a little more detail, we will of course do it in much more detail in the lectures to come. So we are trying to extrapolate. So basically it's a prediction problem,\n",
            "a slightly different presentation of the idea. Okay, so now, as I said, this whole thing so far has been largely a kind of algorithmic problem, right? In some sense, if I fix the set of items and the set of transactions and the set of the two thresholds, the support and the confidence threshold, then for any x, comma y, either it is true or it is not true. So there is a fixed answer. So the answer is known. So this is something where I can actually validate that you have either enumerated all the association rules or you have missed out something. So technically there is no learning involved. It's more an algorithmic question. So how does one connect this to learning? Well, in specific context, you can interpret these rules as classification rules. So, remember we said supervised learning says, if this is there, then it is a fraud. If this thing is not there, then it is not a fraud, and so on. So, let's look at a typical example. So, supposing we have some question which is about\n",
            "whatever, income, stuff like that. So each row in the table will be one item, and there will be a special column which indicates what category, depending on the classification problem that we are dealing with, what category it is. And the goal of supervised learning is to now construct, given a new row, a new item, a new combination of these attributes, which is not seen before, try to predict what would be the most appropriate category to assign. So these items which are given with the labels. So these are called labels. So these items are called training data. So we have labeled training data, which consists of some information which has been collected in the past, some historical information about items and their classification. And we want to find a model that generalizes the training data. So since normally this categorization corresponds to some kind of classification, this is typically called a classification problem. So classification problem could be a binary problem. It\n",
            "So last time we started with supervised learning in earnest, and we were looking at this decision tree model. So, in a decision tree model, you have essentially a table in which the columns are the. So each item, a row in the table and one special column denotes the class that you are trying to classify. And we assumed it's a binary classification. So the class is zero, one, or yes, no, or whatever you want to interpret. The two categories are. So the algorithm was very simple. At a high level, what you want to do is choose an attribute based on the answer to the question that you're asking about that attribute. The data splits, and then you take each partition, ask another question. So that's the thing. And you want to come down and keep asking questions until either you have reached, like these situations here, a partition in which all the values of the class variable are the same. So you have a uniform class level or you have run out of questions, because we can only ask in any path\n",
            "So remember, these x I's are actually not unknowns. These x I's known. So these x I's are what you get. The theta I's are the unknowns that you are trying to figure out. But in terms of the theta I's you can predict for a given xi. If you have computed some theta I's, then the answer is summation theta I x. So therefore the target that we have is clearly to find the best line. So let's assume we have a simple case of only one variable. So we have x one, x two, and so on. So we have n points. In reality, each of these x size is a vector of k, and the y, by convention, is always the label. So in the earlier thing, when we looked at that scikitlearn decision tree thing, we used capital x to denote the input matrix and y to denote the column matrix of output. So this is a normal standard convention in supervised learning that x's denote the inputs of the training data and y denotes the output label. In this case, it's not a label, but it's an output value. So in order to compute the best\n",
            "model, or a numerical prediction model. As we said, in case you're trying to predict a number or category, the category is more like a classification problem, right? I give you something and I want you to classify it as yes, no, good, bad, or we have unsupervised learning where we are looking for some kind of structure, and usually this is in the form of clustering, but we also have to deal with these outliers, as I said. And then sometimes you want to simplify the problem by knocking off certain dimensions or unrolling the object or so. So if you look at the popular press and the popular literature, all the focus of machine learning is actually on the first one. So supervised learning is by far the more attractive and the more, should I say, attractive, I guess it's the more attractive aspect of machine learning. This is what people are really looking for. But unfortunately, as I said, to do effective supervised learning, you need to actually get a lot of training data. And this is\n",
            "its topic is education. And if it has game and team, then it is. So this is a special kind of association rule, where the right hand side of the rule is always a singleton, and it corresponds to a special type of item which is a category, in this case a topic. So when you have a table like this, the rows may have different number of entries. Or if you want to think about it as a table, then some columns may be blank. So not all columns are filled, but there's one last column which is filled. And now you want to now construct these rules corresponding to the first k minus one columns, implying the last column. And this now becomes something where these rules that you get out of this give you a kind of classifier. So this is a kind of a simplistic way of doing supervised learning. So that kind of brings me to the end of this basic treatment of classes, this market basket analysis. So what you're really looking for is correlations between sets of items across transactions, which we\n",
            "So we were looking at this market basket analysis, and towards the end of the discussion on association rule rules, if everybody who buys X is also likely to buy y. We said that one application of this association rule idea is to have these so called class association rules. So the right hand side was a category. We looked at an example with documents and we said, if a document has these words, it is also likely to belong to this category. So that brings us to the topic that is one of the central ones in machine learning, which is the idea of supervised learning. So in supervised learning, we have a set of items, and each item belongs to some category or class, and we distinguish these items in terms of some attributes. So you can think about this, as we will see shortly, you can think about these attributes as columns, right? So the attributes will be things like name, age, date of birth, whatever, income, stuff like that. So each row in the table will be one item, and there will be a\n",
            "set of model predictions. What fraction of these predictions are correct? So, this is what's called accuracy. So, on how much of that test set that I kept aside, on what fraction of the test set did my model make the right prediction? So, the problem is that very often the choice, let us stick to our assumption that we are doing a binary prediction. The choice between the two parts is not symmetric. So the thing we are looking for is very often a minority. So this is a graphic. Blow it up a little bit. So this is saying that if I look at credit card fraud, which is one of the typical examples of where supervised learning is used, right? So we look at different parameters of the transaction, where it was made, what time of day it was made, and how does it compare to other transactions made by the customer and whatever, and the bank wants to know if it's a fraud. So if you actually look at the attempted fraud. So this is going into the future, it's going into 2027. But let us look at\n",
            "to show you some code before we come back to theory. So, is there any further questions? So, at the moment, I'm not expecting you to do anything with this code other than to understand that a, it is relatively painless to invoke a model in scikitlearn. And if you have this kind of visualization code, either you write it yourself or somebody gives it to you. You can then interpret your models visually and then experiment with it by changing things and seeing what happens. And that gives you a fair amount of insight both into your data and into how the model is working. So it gives you some indications about the limitations of that particular. Okay, so now I'm going to do something hopefully not unfamiliar to you. Right? At the beginning, when we talked about supervised learning, we said that we are trying to predict something, and those predictions can be in two types. So one type is what we have seen in the decision tree, which is a classification. So the predicted value is one from a\n",
            "to do effective supervised learning, you need to actually get a lot of training data. And this is sometimes expensive. Very often it is expensive. So unsupervised learning is often the starting. A few. Couple of years back, there were three turing awards given for deep learning. So one of them was given to Jan Lakun. And his observation is that if you think of this whole thing as a cake, then actually most of the cake is actually unsupervised learning. So supervised learning is just a thin layer on the top, but it's like the icing on the cake. So when we go to a bakery and we see an attractive cake, what we're attracted to is the surface, the icing surface. But if the inside is made of sodas, then the cake will not taste good. So you have to be careful not to be fooled by the icing. So the unsupervised learning is also important. But supervised learning is where all the, in some sense, the jazz is. That's what people spend up spending a lot more time on. And we will also probably\n",
            "what you're really looking for is correlations between sets of items across transactions, which we formalize in terms of these association groups. X implies y. And what we saw is that as such, combinatorially, this is a very complicated thing to calculate, given the sizes of the sets involved. But we can use this appropriate principle both to identify the sets which are interesting, those which are frequent enough to be considered, and also to decompose them into rules. So you use the approoriate twice, once to find the frequent z, and second to decompose each frequent z into possible x implies y. And using this, we can build our first simple supervised learning model. So these rules now become a very simple way of prediction. Now, if you give me a document, I will look at what words are there in the document in this previous example. And if it contains the word student and school, I will predict education. If it contains game and team, I'll predict sports. Now, of course, if it has\n",
            "a dog picture from a cat picture, or one which is neither of the two, it's not very easy to quantify that. And there the attributes in a picture are typically just if you think of a picture as a digital picture, it's a bunch of pixels and their colors and their arrangement, their relative arrangement. So even I'm saying, even if you have some domain knowledge, it's not very clear that the person's domain knowledge is aligned to the way the data is available. So what we are going to be doing is agnostic to the domain. So we are not going to believe anything or assume anything about the domain, except that we will want to validate at the end somehow that what we are doing is right. But in practice what you're saying makes sense that really to do supervised learning, it's much more realistic to do it in collaboration with somebody who understands a domain rather than just doing it blindly. Because also when you do it blindly, you might come up with solutions which make no sense. You\n",
            "against some unknown data. So, one other strategy where you don't want to, I mean, one of the other disadvantages of doing this is that maybe that there are some minority anomalies in this data, and the choice of test data that you have made might have hidden all these anomalies, so you never see them, and maybe it's important to see them. So there may be many situations, or maybe you just don't have enough data as a whole to build a good model by only looking at 80%. So another strategy is to systematically do this with different subsets. So what you're really asking at some higher level is that machine learning approach. So, remember, we have seen only decision trees, but we are going to see many models. So there are clearly many ways to build models. And the reason, whenever you see that there are many ways to do something, it's only because there is no guarantee that a given way is the best one. So more or less what you want to validate is, I have, say, seven different strategies\n",
            "things, you break it up into 1000 batches. So you do 1000 points. So you get some averaging out of the behavior of the function, make an adjustment, then you do another 1000, make an adjustment and so on. So all these things are actually used, we will see later in neural networks and all that. But in this linear prediction also, that's where they arise. I mean, that's the origin of this. So this is, of course, as you have all probably read. So this strategy is conventionally called linear regression, but it's basically this iterative linear prediction, which you can do theoretically by a matrix operation, but computationally, it's more feasible to do it in this. So I'll stop here, and we'll continue next time to discuss why we are using some square error and also what to do when you have nonlinear things, how to deal with nonlinear approximations. Having done decision trees, I think at the next class, at the end of the class, the last 15 have a small moodle quiz covering up to last\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install cohere"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVDvdN1E-Y8O",
        "outputId": "b2676e52-e6ec-407f-b398-1cef619855c9"
      },
      "id": "RVDvdN1E-Y8O",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cohere\n",
            "  Downloading cohere-4.56-py3-none-any.whl (52 kB)\n",
            "\u001b[?25l     \u001b[90m\u001b[0m \u001b[32m0.0/52.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.9.3)\n",
            "Requirement already satisfied: backoff<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.2.1)\n",
            "Collecting fastavro<2.0,>=1.8 (from cohere)\n",
            "  Downloading fastavro-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib_metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (6.11.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.7)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (2024.2.2)\n",
            "Installing collected packages: fastavro, cohere\n",
            "Successfully installed cohere-4.56 fastavro-1.9.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cohere\n",
        "co = cohere.Client('w8CnnlzVol2aZEiirZNLUs0onAqXUUYBZCw2Oj7g')"
      ],
      "metadata": {
        "id": "J4ttbycMADKK"
      },
      "id": "J4ttbycMADKK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Query 1 Merge Retriever with Cohere Reranker"
      ],
      "metadata": {
        "id": "oLoMTId7DnZp"
      },
      "id": "oLoMTId7DnZp"
    },
    {
      "cell_type": "code",
      "source": [
        "query_1=\" What are some challenges associated with data collection?\""
      ],
      "metadata": {
        "id": "DGs9YGCdD3Hw"
      },
      "id": "DGs9YGCdD3Hw",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_docs_query1=[]\n",
        "for i in range(len(docs)):\n",
        "  retrieved_docs_query1.append(docs[i].page_content)"
      ],
      "metadata": {
        "id": "Lmr1glvTDTH_"
      },
      "id": "Lmr1glvTDTH_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = co.rerank(query=query_1, documents=retrieved_docs_query1, top_n=3, model='rerank-english-v2.0') # Change top_n to change the number of results returned. If top_n is not passed, all results will be returned.\n",
        "for idx, r in enumerate(results):\n",
        "  print(f\"Document Rank: {idx + 1}, Document Index: {r.index}\")\n",
        "  print(f\"Document: {r.document['text']}\")\n",
        "  print(f\"Relevance Score: {r.relevance_score:.2f}\")\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmHIQ_JuDwk7",
        "outputId": "e72b8f0e-c620-420c-cec8-93c8820ea53e"
      },
      "id": "KmHIQ_JuDwk7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document Rank: 1, Document Index: 0\n",
            "Document: entered by somebody and then converted to electronic forms. So that would be, there would be two levels of potential sources for errors. The person writing down the information and then the person typing in the information. Now, gradually these kind of electronic forms are spilled in directly, so at least the source of the error is reduced to one step. But still, people mistype things. I mean, there are any number of situations where people type their email address wrong and so notifications don't reach them and so on. So there is this data collection. How do you collect the data and how do you clean it? And the third thing is, how do you make it uniform? So when data is being collected by different people, they may collect different things. And for instance, if you look at the government, typically the government collects data in different forms. For instance, there is a public distribution system which the ration shops, so they collect some information about who is collecting ration\n",
            "Relevance Score: 0.92\n",
            "\n",
            "\n",
            "Document Rank: 2, Document Index: 12\n",
            "Document: we have to realize that different people with the same bit different symptoms. So conversely, two people with the same symptoms don't necessarily. So there are asymptomatic COVID patients. There are people who have a sore throat and a cold and a headache who don't necessarily have COVID. So I cannot just say that if you have these symptoms, you must have COVID, and if you don't have these symptoms, you cannot have COVID. Right. So clearly there is something going on in the background, and that background in our case is revealed through a test. Even tests have errors and all that. So it's really a problem that we have to grapple with in real life. And we will just assume for now that when we reach such a situation, we just take a majority decision. But realistically, if we get too many of these situations, and it's very difficult to decide, we have to ask whether the data has actually been collected correctly. So as we said, the main issue is really how to ask the questions and what\n",
            "Relevance Score: 0.76\n",
            "\n",
            "\n",
            "Document Rank: 3, Document Index: 2\n",
            "Document: been collected correctly. So as we said, the main issue is really how to ask the questions and what this means. Sorry, sir, I have a question. Yeah. Sir, once we know that the data is young, we are making a prediction and it come out that young. So like other attribute is not relevant other than it has job or not, and then we are not going to look at other attributes. Yeah, but remember that which attributes to look like vary from one path to another. So maybe in this case, right, so what we are saying is that if they are young, we only need the job, right? But if they are middle aged, we need to know the house. So for different combinations, so they may not occur together. I agree, in any decision, but each of these plays a role somewhere. Now, if there is another attribute which never plays a role, as we will see the next tree as that example. Right? So if you look at this, this is a different tree for the same data set. So instead of first asking the age, we ask whether you own a\n",
            "Relevance Score: 0.62\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Query 2"
      ],
      "metadata": {
        "id": "__SC-vghERKz"
      },
      "id": "__SC-vghERKz"
    },
    {
      "cell_type": "code",
      "source": [
        "query_2=\" What are the advantages of the Apriori algorithm?\""
      ],
      "metadata": {
        "id": "_qhcYE8TEUpX"
      },
      "id": "_qhcYE8TEUpX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_docs_query2=[]\n",
        "for i in range(len(docs)):\n",
        "  retrieved_docs_query2.append(docs[i].page_content)"
      ],
      "metadata": {
        "id": "XpbLdyknBEcD"
      },
      "id": "XpbLdyknBEcD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = co.rerank(query=query_2, documents=retrieved_docs_query2, top_n=3, model='rerank-english-v2.0') # Change top_n to change the number of results returned. If top_n is not passed, all results will be returned.\n",
        "for idx, r in enumerate(results):\n",
        "  print(f\"Document Rank: {idx + 1}, Document Index: {r.index}\")\n",
        "  print(f\"Document: {r.document['text']}\")\n",
        "  print(f\"Relevance Score: {r.relevance_score:.2f}\")\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaFPkfrDE649",
        "outputId": "ff03e71f-7cb6-496d-9905-6f70ceeac7d6"
      },
      "id": "IaFPkfrDE649",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document Rank: 1, Document Index: 3\n",
            "Document: against some unknown data. So, one other strategy where you don't want to, I mean, one of the other disadvantages of doing this is that maybe that there are some minority anomalies in this data, and the choice of test data that you have made might have hidden all these anomalies, so you never see them, and maybe it's important to see them. So there may be many situations, or maybe you just don't have enough data as a whole to build a good model by only looking at 80%. So another strategy is to systematically do this with different subsets. So what you're really asking at some higher level is that machine learning approach. So, remember, we have seen only decision trees, but we are going to see many models. So there are clearly many ways to build models. And the reason, whenever you see that there are many ways to do something, it's only because there is no guarantee that a given way is the best one. So more or less what you want to validate is, I have, say, seven different strategies\n",
            "Relevance Score: 0.35\n",
            "\n",
            "\n",
            "Document Rank: 2, Document Index: 6\n",
            "Document: what you're really looking for is correlations between sets of items across transactions, which we formalize in terms of these association groups. X implies y. And what we saw is that as such, combinatorially, this is a very complicated thing to calculate, given the sizes of the sets involved. But we can use this appropriate principle both to identify the sets which are interesting, those which are frequent enough to be considered, and also to decompose them into rules. So you use the approoriate twice, once to find the frequent z, and second to decompose each frequent z into possible x implies y. And using this, we can build our first simple supervised learning model. So these rules now become a very simple way of prediction. Now, if you give me a document, I will look at what words are there in the document in this previous example. And if it contains the word student and school, I will predict education. If it contains game and team, I'll predict sports. Now, of course, if it has\n",
            "Relevance Score: 0.32\n",
            "\n",
            "\n",
            "Document Rank: 3, Document Index: 8\n",
            "Document: have to do a search through all possible trees. So instead we wanted to use some heuristic. So the main question that we have to ask is, which attribute do we query next at any stage. So our goal is to achieve this partition, which is pure, where all the values are yes or all the values are no. So we try to accelerate towards that. So that is this greedy strategy. So we use a heuristic, which will reduce the impurity as much as possible. And when we move from one node to its children by asking a question, what we do is we compute a weighted average. So for each node we can compute the impurity. But then when we combine the children of a node to get the impurity at the next level, we use a weighted average. So going simple weighted average just assigns a weight one to every item. So you just take the fraction. So for node one, you take the fraction of instances in that partition, multiply that fraction by the impurity and so on, and add it up, and we choose the one which reduces. So\n",
            "Relevance Score: 0.30\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Query 3"
      ],
      "metadata": {
        "id": "ItFKtqngFyYB"
      },
      "id": "ItFKtqngFyYB"
    },
    {
      "cell_type": "code",
      "source": [
        "query_3=\" What distinguishes training data in supervised learning, and what is its purpose? \""
      ],
      "metadata": {
        "id": "pby-49QVF4l6"
      },
      "id": "pby-49QVF4l6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_docs_query3=[]\n",
        "for i in range(len(docs)):\n",
        "  retrieved_docs_query3.append(docs[i].page_content)"
      ],
      "metadata": {
        "id": "NIdqvsLnGVuv"
      },
      "id": "NIdqvsLnGVuv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = co.rerank(query=query_3, documents=retrieved_docs_query3, top_n=3, model='rerank-english-v2.0') # Change top_n to change the number of results returned. If top_n is not passed, all results will be returned.\n",
        "for idx, r in enumerate(results):\n",
        "  print(f\"Document Rank: {idx + 1}, Document Index: {r.index}\")\n",
        "  print(f\"Document: {r.document['text']}\")\n",
        "  print(f\"Relevance Score: {r.relevance_score:.2f}\")\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hBLz3hS3F2m-",
        "outputId": "8a5069b8-fe6c-44cc-98dc-7d84cba1a422"
      },
      "id": "hBLz3hS3F2m-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document Rank: 1, Document Index: 2\n",
            "Document: whatever, income, stuff like that. So each row in the table will be one item, and there will be a special column which indicates what category, depending on the classification problem that we are dealing with, what category it is. And the goal of supervised learning is to now construct, given a new row, a new item, a new combination of these attributes, which is not seen before, try to predict what would be the most appropriate category to assign. So these items which are given with the labels. So these are called labels. So these items are called training data. So we have labeled training data, which consists of some information which has been collected in the past, some historical information about items and their classification. And we want to find a model that generalizes the training data. So since normally this categorization corresponds to some kind of classification, this is typically called a classification problem. So classification problem could be a binary problem. It\n",
            "Relevance Score: 0.99\n",
            "\n",
            "\n",
            "Document Rank: 2, Document Index: 0\n",
            "Document: a specification, but generating a concrete program from a generic program you can think of a model template as. So I just give you a line here which says a Y equal to Mx plus c. And here I want a specific m zero and C zero, which fits the given data in the best possible way, which is also part of the description of the algorithm. What does it mean for one line to be better than another line? So that's part of it. So the other side of this picture, as I mentioned, is when you don't have this training data, you don't have any examples that people have already labeled, but you are looking for some kind of patterns. So there is no guidance. So the thing about supervised learning is somebody should have gone through and given you this information before. Now, this information could have been collected over time. Maybe it's not manually collected, like the school marks. The school marks over time. Everybody has. I mean, the school keeps a record of what happens in the model exams, what\n",
            "Relevance Score: 0.90\n",
            "\n",
            "\n",
            "Document Rank: 3, Document Index: 5\n",
            "Document: the data. So what we are trying to do is learn some kind of mathematical models from data. And this falls into two broad categories. So the first category is where you are given examples. So you are told, for instance, this is, for example, supposing you're trying to evaluate whether a painting is painted by a particular type of. So there are these pools of painting, like impressionists and cubists and so on. So you might be given a lot of pictures saying, this is cubist, this is not cubist, this is impressionist, and so on. And then from these examples which are given to you with manual information, you are supposed to build a model which will take an unknown painting and tell you from its features which of these categories. So this is a typical supervised learning kind of thing. Unsupervised learning is something which is closer to the data mining situation where you have data and you are looking for patterns, but you don't really have a clear idea beforehand what patterns they are.\n",
            "Relevance Score: 0.86\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### query 4"
      ],
      "metadata": {
        "id": "m1hd4OrnGqvo"
      },
      "id": "m1hd4OrnGqvo"
    },
    {
      "cell_type": "code",
      "source": [
        "query_4=\" What is cross-validation?\""
      ],
      "metadata": {
        "id": "EySRfbG6GqQJ"
      },
      "id": "EySRfbG6GqQJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retrieved_docs_query4=[]\n",
        "for i in range(len(docs)):\n",
        "  retrieved_docs_query4.append(docs[i].page_content)"
      ],
      "metadata": {
        "id": "Abc2DEQrHYZ_"
      },
      "id": "Abc2DEQrHYZ_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = co.rerank(query=query_4, documents=retrieved_docs_query4, top_n=3, model='rerank-english-v2.0') # Change top_n to change the number of results returned. If top_n is not passed, all results will be returned.\n",
        "for idx, r in enumerate(results):\n",
        "  print(f\"Document Rank: {idx + 1}, Document Index: {r.index}\")\n",
        "  print(f\"Document: {r.document['text']}\")\n",
        "  print(f\"Relevance Score: {r.relevance_score:.2f}\")\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsE3-bRQHe4E",
        "outputId": "ffc7bc57-03f2-4027-90c9-ad94b9fa3121"
      },
      "id": "CsE3-bRQHe4E",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document Rank: 1, Document Index: 3\n",
            "Document: distribution changes slightly, one attribute might get better entropy than another attribute. And you will choose that question first. So the shape of the tree might vary a lot between these, so you may not get the same. Okay, so the question about cross validation, cross validation. What I'm saying is that you do not make a hard and fast choice once and for all to split your data this way. So you're taking your data and you're saying, hey, first let me leave out this 20% and build one model. So I am building multiple models. I'm building m one, m two, m three, m four, and m five. Each of these models is built using 80% of the test data, but a different 80%. So each of them leaves out some 20%. So I'm building five different models and comparing what I see in all these five. So the first thing is that if this approach is good, then in general, these five models should behave in a similar way with respect to the outcome. So if they all behave similarly, then I can decide what to do. So\n",
            "Relevance Score: 0.92\n",
            "\n",
            "\n",
            "Document Rank: 2, Document Index: 8\n",
            "Document: the best one. So more or less what you want to validate is, I have, say, seven different strategies to solve this problem using machine learning. And I want to check which one of them is good. So I need to compare. So once I compare, then I'm stuck with whatever I have. It may be that this gives me only 70% accuracy or some such metric, but the other models give me even less. So it's more really a comparative statement to start with, which is, is this method actually giving me something reasonable? And is it giving me better something than something else? So, for this one strategy is so called cross validation. So what you do is you take some fraction, say, in this case, it is one fifth. So 20%. So you take your data and you leave out. So you randomize it into five groups, which preserve, in some sense, the random behavior, so they partition it five ways. So if I leave out any one of these groups, it's as though I have taken the remaining 80% for training and this 20% for test. But\n",
            "Relevance Score: 0.91\n",
            "\n",
            "\n",
            "Document Rank: 3, Document Index: 1\n",
            "Document: a fixed data set, and you are going to apply it to some other data set which you have not seen. So will that generalize well or not is the biggest question in machine learning. How do you know that the training data that you have used to build your model is actually representative of the data that you see in the real. And there could be many reasons why it is not valid. It could be because of sampling. So, for instance, you might be building a model for some consumer behavior by looking at one segment of. Maybe you are looking at the behavior of people who are in their, are building a model of how people behave, but your actual market consists of people who are maybe in their 40s, who have a very different way of dealing with things. So you need to be careful that the data that you're looking at is actually representative. So this is a huge problem and there's no correct answer. You can measure it, but you cannot. In some sense, if you could validate it, then this whole problem\n",
            "Relevance Score: 0.85\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Query 5"
      ],
      "metadata": {
        "id": "OnFLlmukHvk_"
      },
      "id": "OnFLlmukHvk_"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eE5M6rBXHu6T"
      },
      "id": "eE5M6rBXHu6T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query=\"What is the process of building the decision tree classifier, and how is it trained on the dataset?\"\n"
      ],
      "metadata": {
        "id": "xmlHBzMRAL2I"
      },
      "id": "xmlHBzMRAL2I",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = co.rerank(query=query, documents=retrieved_docs, top_n=3, model='rerank-english-v2.0') # Change top_n to change the number of results returned. If top_n is not passed, all results will be returned.\n",
        "for idx, r in enumerate(results):\n",
        "  print(f\"Document Rank: {idx + 1}, Document Index: {r.index}\")\n",
        "  print(f\"Document: {r.document['text']}\")\n",
        "  print(f\"Relevance Score: {r.relevance_score:.2f}\")\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdTjpPSWB_Vp",
        "outputId": "b9ebe7d7-12b8-42a7-d83d-ef5336c0dcae"
      },
      "id": "EdTjpPSWB_Vp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Document Rank: 1, Document Index: 9\n",
            "Document: and is therefore picking up some peculiarities which don't necessarily exist within. So one of the things we mentioned in passing was that we like short trees for two reasons. One is because they are easier to explain. The second thing, which I claim without any justification, is that they generalize better. So here, priority, they are saying, let us not construct deep trees. So whatever tree we construct, we are going to stop it when it reaches. So it's a two step process, right? So what you do is you first say what are the parameters for the decision tree classifier? So he says, I want a decision tree classifier to be set up with this random state 42 and which will not grow to more than depth two. And then I have to actually construct the classifier for a particular data set. So that's the next thing. So I use this fit function, right? In some sense this creates a decision tree object with certain operating parameters, and then you pass it the training data in the form of the input\n",
            "Relevance Score: 0.99\n",
            "\n",
            "\n",
            "Document Rank: 2, Document Index: 14\n",
            "Document: and two, three are the petal. So it's taking all the rows and it's taking the third and fourth columns. So we're throwing away two columns. So we are making it, instead of a four column array, we are making it into a two column array. And in this data. So when you load the data set, it automatically produces these two subparts, iris data and iris target. So target is the classification variable. Remember, in this case, the classification variable is a three way thing, right? There are three types of irises that we saw, so it will be essentially a number, zero, one. And now to get this decision tree classifier, we have to take this function that we have imported. So we say take a decision tree classifier. We have to provide it with, again some random state because it uses some randomization inside it. And now this is something which we have not talked about. So we discussed that we will build a decision tree normally until we either achieve some pure leaf nodes where the classification\n",
            "Relevance Score: 0.98\n",
            "\n",
            "\n",
            "Document Rank: 3, Document Index: 3\n",
            "Document: So last time we started with supervised learning in earnest, and we were looking at this decision tree model. So, in a decision tree model, you have essentially a table in which the columns are the. So each item, a row in the table and one special column denotes the class that you are trying to classify. And we assumed it's a binary classification. So the class is zero, one, or yes, no, or whatever you want to interpret. The two categories are. So the algorithm was very simple. At a high level, what you want to do is choose an attribute based on the answer to the question that you're asking about that attribute. The data splits, and then you take each partition, ask another question. So that's the thing. And you want to come down and keep asking questions until either you have reached, like these situations here, a partition in which all the values of the class variable are the same. So you have a uniform class level or you have run out of questions, because we can only ask in any path\n",
            "Relevance Score: 0.94\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "52722c76d9494196913c3f23b1478b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b227e7088bcd49e885ba9d4ce9aa8560",
              "IPY_MODEL_57c613027ba34100aa985539d03cfb26",
              "IPY_MODEL_4e7f9aed3d244e4b91ba2d5b62febb09"
            ],
            "layout": "IPY_MODEL_72daefc4f5ba48d99cc221ccc87fc0b9"
          }
        },
        "b227e7088bcd49e885ba9d4ce9aa8560": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1b4a13aca454b0fa06de24d8ebd2702",
            "placeholder": "",
            "style": "IPY_MODEL_82420dfcf16c497087e1965e7aa2e100",
            "value": "modules.json:100%"
          }
        },
        "57c613027ba34100aa985539d03cfb26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d576306dad004d23b262099730b1f8ff",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8655fb9499f24995b6fb7c60035d0a34",
            "value": 349
          }
        },
        "4e7f9aed3d244e4b91ba2d5b62febb09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53e49897eb1e40b39b7f5c549eb456d8",
            "placeholder": "",
            "style": "IPY_MODEL_21b86c7634e64142a7d29a00b0709b60",
            "value": "349/349[00:00&lt;00:00,14.5kB/s]"
          }
        },
        "72daefc4f5ba48d99cc221ccc87fc0b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1b4a13aca454b0fa06de24d8ebd2702": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82420dfcf16c497087e1965e7aa2e100": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d576306dad004d23b262099730b1f8ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8655fb9499f24995b6fb7c60035d0a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53e49897eb1e40b39b7f5c549eb456d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21b86c7634e64142a7d29a00b0709b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83a4b30bd4b545edb4e0c2eca0f22548": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e886d5383b8447390bb2208fd943872",
              "IPY_MODEL_63b48bdfe3284acabab332a14c821651",
              "IPY_MODEL_ecee89595dde487b9b16084855e3c138"
            ],
            "layout": "IPY_MODEL_6d680f5aa55f4455b9973b21cedf6969"
          }
        },
        "3e886d5383b8447390bb2208fd943872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdb8f3069ffc411482db4bfa8a0889e1",
            "placeholder": "",
            "style": "IPY_MODEL_ebc44c8e38004170aee04b241ca7a730",
            "value": "config_sentence_transformers.json:100%"
          }
        },
        "63b48bdfe3284acabab332a14c821651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_993990dbed0b4ea797f44a98f0ae0d2c",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_737429dcdfc4400c80535c4d3021362f",
            "value": 124
          }
        },
        "ecee89595dde487b9b16084855e3c138": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5467eb7115c744f096fddcdbfd1473f5",
            "placeholder": "",
            "style": "IPY_MODEL_e603d283ca6544e4b4af596af24b3113",
            "value": "124/124[00:00&lt;00:00,3.09kB/s]"
          }
        },
        "6d680f5aa55f4455b9973b21cedf6969": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdb8f3069ffc411482db4bfa8a0889e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebc44c8e38004170aee04b241ca7a730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "993990dbed0b4ea797f44a98f0ae0d2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "737429dcdfc4400c80535c4d3021362f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5467eb7115c744f096fddcdbfd1473f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e603d283ca6544e4b4af596af24b3113": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "947bce9f66af49c8b1e9d20447bd8174": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57728d7a626844ef9ce0def421a9439a",
              "IPY_MODEL_911eedb7d6bd47b3bb37c95855e0c746",
              "IPY_MODEL_7e1daecb0bde48c2a396552b91ccdb7d"
            ],
            "layout": "IPY_MODEL_400d377889c743caa1ae6037503a958b"
          }
        },
        "57728d7a626844ef9ce0def421a9439a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb48cb33873146baaed8154b020098ca",
            "placeholder": "",
            "style": "IPY_MODEL_c8f1cc6e5ab548f1ac2da5aef4f416b5",
            "value": "README.md:100%"
          }
        },
        "911eedb7d6bd47b3bb37c95855e0c746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f3b578a95f343b09553c173683a1156",
            "max": 90272,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9b2dd7d4d6bb4e5f87dbc67d136979f3",
            "value": 90272
          }
        },
        "7e1daecb0bde48c2a396552b91ccdb7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f01326ac2a140ebb155720b5b19efdc",
            "placeholder": "",
            "style": "IPY_MODEL_5b75481deec3498bbf0ef05056afd5d7",
            "value": "90.3k/90.3k[00:00&lt;00:00,1.25MB/s]"
          }
        },
        "400d377889c743caa1ae6037503a958b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb48cb33873146baaed8154b020098ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8f1cc6e5ab548f1ac2da5aef4f416b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3f3b578a95f343b09553c173683a1156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b2dd7d4d6bb4e5f87dbc67d136979f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9f01326ac2a140ebb155720b5b19efdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b75481deec3498bbf0ef05056afd5d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bae66bb241b447e0bf0b1fc1666a294f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_75d22f1876494c9787bddabb3190350f",
              "IPY_MODEL_b21aa4a9277d4ce2ae4b7f09717b3d1a",
              "IPY_MODEL_1ba37c69aece4519bb276bb46e6ad74c"
            ],
            "layout": "IPY_MODEL_4f01964b42fb449cbbfed139503eaf0e"
          }
        },
        "75d22f1876494c9787bddabb3190350f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f70f0da54c4430998ee42d34c58f53d",
            "placeholder": "",
            "style": "IPY_MODEL_fa41f3d4b4a64f0881c6433052c026ba",
            "value": "sentence_bert_config.json:100%"
          }
        },
        "b21aa4a9277d4ce2ae4b7f09717b3d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88acdf70f2b743a5833ba8e1461eed65",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_05859f0a72544fc182713af8a5337238",
            "value": 52
          }
        },
        "1ba37c69aece4519bb276bb46e6ad74c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c0ce833a0554e10a5087f73bb5d6d7c",
            "placeholder": "",
            "style": "IPY_MODEL_cc440aff42e94f41a2ec255012d4c730",
            "value": "52.0/52.0[00:00&lt;00:00,2.21kB/s]"
          }
        },
        "4f01964b42fb449cbbfed139503eaf0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f70f0da54c4430998ee42d34c58f53d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa41f3d4b4a64f0881c6433052c026ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88acdf70f2b743a5833ba8e1461eed65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05859f0a72544fc182713af8a5337238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3c0ce833a0554e10a5087f73bb5d6d7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc440aff42e94f41a2ec255012d4c730": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2ce8bce3fea4b57a82d30908f57dd12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_caa7c33de4a1432f84bdc2f622ebbe69",
              "IPY_MODEL_63b551023b4844a68dd45aa8431063ad",
              "IPY_MODEL_222912e65207443988f2141c4a9617f9"
            ],
            "layout": "IPY_MODEL_b1b3f40102004a9c9c64b5a243abdcf8"
          }
        },
        "caa7c33de4a1432f84bdc2f622ebbe69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9732e1248f74903aff8a62d443bb1e9",
            "placeholder": "",
            "style": "IPY_MODEL_96f9ef30dbab4bf2a81d9ab1a9c49699",
            "value": "config.json:100%"
          }
        },
        "63b551023b4844a68dd45aa8431063ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60c1e5a5dbe24e078e6affad3acbf797",
            "max": 720,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cb0eb05e12314f089595a66469d51901",
            "value": 720
          }
        },
        "222912e65207443988f2141c4a9617f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f2783168c8d4ea1bda110b40f0a28c7",
            "placeholder": "",
            "style": "IPY_MODEL_c83956f92b044f159831105d4c49d9cf",
            "value": "720/720[00:00&lt;00:00,29.6kB/s]"
          }
        },
        "b1b3f40102004a9c9c64b5a243abdcf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9732e1248f74903aff8a62d443bb1e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96f9ef30dbab4bf2a81d9ab1a9c49699": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60c1e5a5dbe24e078e6affad3acbf797": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb0eb05e12314f089595a66469d51901": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f2783168c8d4ea1bda110b40f0a28c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c83956f92b044f159831105d4c49d9cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "667448ad74f24ce5b09800391b5515f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_00b334f4920f4e6089ae6acf9117416b",
              "IPY_MODEL_7cb5b7b3fc1c4d48aa96df6ebacc3761",
              "IPY_MODEL_179f48b91e94447d98d206e1fe425d69"
            ],
            "layout": "IPY_MODEL_ee8bfdb734054c778f95d146219c3765"
          }
        },
        "00b334f4920f4e6089ae6acf9117416b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5683ae50342f4cd0b650ae7cada9fdf1",
            "placeholder": "",
            "style": "IPY_MODEL_e4d830beca6049d98871fc838e3c8a8c",
            "value": "model.safetensors:100%"
          }
        },
        "7cb5b7b3fc1c4d48aa96df6ebacc3761": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5079159317554c6a993a1b06cfba923b",
            "max": 1340616616,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20031b89edb34382b6dd355944c7b76b",
            "value": 1340616616
          }
        },
        "179f48b91e94447d98d206e1fe425d69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7da5cb654f8d433fb8c5f2cbc09566fc",
            "placeholder": "",
            "style": "IPY_MODEL_91714fc0c83b417b8e51689b7cfa1b7c",
            "value": "1.34G/1.34G[00:10&lt;00:00,45.7MB/s]"
          }
        },
        "ee8bfdb734054c778f95d146219c3765": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5683ae50342f4cd0b650ae7cada9fdf1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4d830beca6049d98871fc838e3c8a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5079159317554c6a993a1b06cfba923b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20031b89edb34382b6dd355944c7b76b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7da5cb654f8d433fb8c5f2cbc09566fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91714fc0c83b417b8e51689b7cfa1b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55f2f2c7868b4cc68948877a05dded73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a2aeab7aa8f418e8cef2cf4d05fc104",
              "IPY_MODEL_5045a97a2df54f9b83e32914a3f1f248",
              "IPY_MODEL_29f5337b0eda48fd8bb1607f734fccf7"
            ],
            "layout": "IPY_MODEL_7b03263645b54559947e00e5d846e0ca"
          }
        },
        "4a2aeab7aa8f418e8cef2cf4d05fc104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f44b57430fc841dfa9b05a23e502b9e7",
            "placeholder": "",
            "style": "IPY_MODEL_1753b069772940f499372daa478d060c",
            "value": "tokenizer_config.json:100%"
          }
        },
        "5045a97a2df54f9b83e32914a3f1f248": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b854e636dc2b471dbe344af781c24c3b",
            "max": 366,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b99aac606454a61b8d6b9da2fb4c88a",
            "value": 366
          }
        },
        "29f5337b0eda48fd8bb1607f734fccf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6596d8fcd4df4ece81d53797fc449152",
            "placeholder": "",
            "style": "IPY_MODEL_3745233681524ab688f596c323deda22",
            "value": "366/366[00:00&lt;00:00,15.2kB/s]"
          }
        },
        "7b03263645b54559947e00e5d846e0ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f44b57430fc841dfa9b05a23e502b9e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1753b069772940f499372daa478d060c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b854e636dc2b471dbe344af781c24c3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b99aac606454a61b8d6b9da2fb4c88a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6596d8fcd4df4ece81d53797fc449152": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3745233681524ab688f596c323deda22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b8e8afea10a46aabf54f563f1e14903": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e051a42886048d5901bcffed3554b14",
              "IPY_MODEL_825a934bef3443479eda76bfc1c4426a",
              "IPY_MODEL_4d19c4411b8648d9a71e305f976f67c9"
            ],
            "layout": "IPY_MODEL_410a036dd20c4bad805a3c5564bde39d"
          }
        },
        "4e051a42886048d5901bcffed3554b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d4b0f57b4044a8c83924fca82ef6aaf",
            "placeholder": "",
            "style": "IPY_MODEL_967a9a42d1964637a7fc70bce9f9a946",
            "value": "vocab.txt:100%"
          }
        },
        "825a934bef3443479eda76bfc1c4426a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cabd809012e844968303073872cb0f0d",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a78668de689646c5b73a207280ea55ab",
            "value": 231508
          }
        },
        "4d19c4411b8648d9a71e305f976f67c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec9f377b00574bb8a77f9392853ca44a",
            "placeholder": "",
            "style": "IPY_MODEL_600d8b87767c434db33df36ff2124768",
            "value": "232k/232k[00:00&lt;00:00,1.74MB/s]"
          }
        },
        "410a036dd20c4bad805a3c5564bde39d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d4b0f57b4044a8c83924fca82ef6aaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "967a9a42d1964637a7fc70bce9f9a946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cabd809012e844968303073872cb0f0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a78668de689646c5b73a207280ea55ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ec9f377b00574bb8a77f9392853ca44a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "600d8b87767c434db33df36ff2124768": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d06e51dd6bba44c6a38b72f26b8ebc1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b46aaec5e0ea4478bf4026ffc1c82875",
              "IPY_MODEL_782e783d8de1471d9449848e655ecd5d",
              "IPY_MODEL_98724648be1e45fbafbcd2368bef2028"
            ],
            "layout": "IPY_MODEL_8ab31c4b2afc41a89b874f728c3cce6d"
          }
        },
        "b46aaec5e0ea4478bf4026ffc1c82875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f323909a0504b81a8432aa6eb26be36",
            "placeholder": "",
            "style": "IPY_MODEL_f21731ddabf64d8cbb55c8b6d7b8513d",
            "value": "tokenizer.json:100%"
          }
        },
        "782e783d8de1471d9449848e655ecd5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2c9de03b9b7417a84e1027537cfe7b4",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e3f1e0f6e564592ad62b275a42172bc",
            "value": 711396
          }
        },
        "98724648be1e45fbafbcd2368bef2028": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7f8e72e9a7047e2b6992f89659df712",
            "placeholder": "",
            "style": "IPY_MODEL_76bf61fa2f26429580bbdd58f2a26ec1",
            "value": "711k/711k[00:00&lt;00:00,3.55MB/s]"
          }
        },
        "8ab31c4b2afc41a89b874f728c3cce6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f323909a0504b81a8432aa6eb26be36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f21731ddabf64d8cbb55c8b6d7b8513d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2c9de03b9b7417a84e1027537cfe7b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e3f1e0f6e564592ad62b275a42172bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7f8e72e9a7047e2b6992f89659df712": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76bf61fa2f26429580bbdd58f2a26ec1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "058425f9a19d4156bb815c12009b38a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3bccc588c88641ed8a8da355234c0908",
              "IPY_MODEL_5bd49c7001aa4bf0b3c5678462c64aa9",
              "IPY_MODEL_729c86c2dae9481db49831a99d496576"
            ],
            "layout": "IPY_MODEL_ef83cdbd05a04521be1ed3fee589e38f"
          }
        },
        "3bccc588c88641ed8a8da355234c0908": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aed5b831f46348bab5565ede4b5ca8f2",
            "placeholder": "",
            "style": "IPY_MODEL_7a591bdc180a4df98f3f2c1a94f2e22e",
            "value": "special_tokens_map.json:100%"
          }
        },
        "5bd49c7001aa4bf0b3c5678462c64aa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b0848ad88304a9c86aac7acc005c7f0",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_252a1633735d4ef7a67a4f1ef22c2204",
            "value": 125
          }
        },
        "729c86c2dae9481db49831a99d496576": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2bf684f637c437baa5a1edf103cd0b7",
            "placeholder": "",
            "style": "IPY_MODEL_6cafd6635d8e49439968bf7a91a526df",
            "value": "125/125[00:00&lt;00:00,5.16kB/s]"
          }
        },
        "ef83cdbd05a04521be1ed3fee589e38f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aed5b831f46348bab5565ede4b5ca8f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a591bdc180a4df98f3f2c1a94f2e22e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b0848ad88304a9c86aac7acc005c7f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "252a1633735d4ef7a67a4f1ef22c2204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d2bf684f637c437baa5a1edf103cd0b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cafd6635d8e49439968bf7a91a526df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "277dc925a8b3456b995d3d05d2acfe65": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46f29f90caae4b8991a7315d7fe88bbc",
              "IPY_MODEL_090e88d6bd9d4d9e9f1e1a938cfe8568",
              "IPY_MODEL_81b154d1b96d4c5db5c9bda2a1a5bfa3"
            ],
            "layout": "IPY_MODEL_68b1f2f9cd094eef9f5daab6a17d0062"
          }
        },
        "46f29f90caae4b8991a7315d7fe88bbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8975b5b0fb494ef1977804162ab484b3",
            "placeholder": "",
            "style": "IPY_MODEL_d42dd22eb10549a298baf795a275353d",
            "value": "1_Pooling/config.json:100%"
          }
        },
        "090e88d6bd9d4d9e9f1e1a938cfe8568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e73e76cb1f044e29b4e8feaadcb49fe",
            "max": 191,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2409eaac25084d23ba1e937886129785",
            "value": 191
          }
        },
        "81b154d1b96d4c5db5c9bda2a1a5bfa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e94231cb64b4b708bbc9ddcda0891b9",
            "placeholder": "",
            "style": "IPY_MODEL_7fe6dac60d74454da08d39f898cba0cb",
            "value": "191/191[00:00&lt;00:00,7.81kB/s]"
          }
        },
        "68b1f2f9cd094eef9f5daab6a17d0062": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8975b5b0fb494ef1977804162ab484b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d42dd22eb10549a298baf795a275353d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e73e76cb1f044e29b4e8feaadcb49fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2409eaac25084d23ba1e937886129785": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e94231cb64b4b708bbc9ddcda0891b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fe6dac60d74454da08d39f898cba0cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}